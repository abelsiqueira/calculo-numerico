<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/calculo-numerico/libs/katex/katex.min.css"> <link rel=stylesheet  href="/calculo-numerico/libs/highlight/github.min.css"> <link href="/calculo-numerico/css/bootstrap.min.css" rel=stylesheet  crossorigin=anonymous > <link href="https://fonts.googleapis.com/css2?family=Cinzel&family=Lato&family=Montserrat&display=swap" rel=stylesheet > <link rel=icon  href="/calculo-numerico/assets/favicon.png"> <link rel=stylesheet  href="/calculo-numerico/css/code-katex.css"> <link rel=stylesheet  href="/calculo-numerico/css/custom.css"> <link rel=stylesheet  href="/calculo-numerico/css/dark-mode.css"> <title>Zeros de funções</title> <header> <nav class="navbar navbar-expand-lg"> <div class=container-fluid > <a class="navbar-brand text-end" href="/calculo-numerico/">Abel S.<br>Siqueira</a> <button class=navbar-toggler  type=button  data-bs-toggle=collapse  data-bs-target="#navbarSupportedContent" aria-controls=navbarSupportedContent  aria-expanded=false  aria-label="Toggle navigation"> <span class=navbar-toggler-icon ></span> </button> <div class="collapse navbar-collapse" id=navbarSupportedContent > <ul class="navbar-nav ms-auto mb-2 mb-lg-0"> <li class=nav-item ><a class=nav-link  href="/calculo-numerico/">Home</a> <li class=nav-item ><a class=nav-link  href="/calculo-numerico/julia/">Julia</a> <li class=nav-item ><a class=nav-link  href="/calculo-numerico/research/">Research</a> <li class=nav-item ><a class=nav-link  href="/calculo-numerico/ufpr/">UFPR</a> </ul> <div class="dark-switch form-check form-switch"> <input type=checkbox  class=form-check-input  id=darkSwitch  /> <label class=custom-control-label  for=darkSwitch >Dark Mode</label> </div> <script src="/calculo-numerico/libs/dark-mode-switch.min.js"></script> </div> </div> </nav> </header> <div class=container-fluid > <div class="container main-text"> <div class=franklin-content ><h1 id="zeros_de_função"><a href="#zeros_de_função" class=header-anchor >Zeros de Função</a></h1> <p>Em muitas situações práticas, estamos interessados em encontrar uma solução de uma equação não linear. Quando a equação tem alguma forma especial, como as equações afins e quadráticas, a solução pode ser obtida facilmente. Em alguns casos, uma equação aparentemente complicada pode ter uma solução através de alguns truques. Por exemplo, a equação</p> \[ 4^{x} - 5\times2^{x} + 6 = 0, \] <p>pode ser resolvida considerando \(y = 2^x\) e resolvendo uma equação quadrática.</p> <p>No entanto, existem casos em que não é fácil encontrar essa solução, ou ainda que não é possível. O exemplo mais clássico disso é a equação</p> \[ xe^x = 1, \] <p>cuja solução é a constante \(\Omega\), com valor perto de \(0.567\). Essa constante, como \(\pi\) e \(e\), é transcedental.</p> <p>De uma maneira mais geral, dado uma função \(f\) contínua num intervalo \([a,b]\), procuramos ao menos um valor de \(x \in [a,b]\) tal que</p> \[ f(x) = 0. \] <p>Uma aplicação um pouco mais prático é o de encontrar a taxa de juros de uma compra feita utilizando um financiamento pela tabela Price. Por exemplo, no financiamento de um carro. A equação que relaciona os valores da tabela Price é</p> \[ p = V \frac{ (1+i)^n i }{ (1 + i)^n - 1},\] <p>onde \(p\) é o valor da parcela, \(V\) é o valor do produto pago à vista no presente, \(n\) é o número de parcelas e \(i\) é a taxa de Juros. Note que para \(i = 0\) essa equação não está definida, no entanto, faz sentido que</p> <ul> <li><p>fisicamente, se não temos juros, temos uma divisão normal: \(p = \dfrac{V}{n}\),</p> <li><p>matematicamente, quando \(i \to 0\), temos</p> </ul> <pre><code class=language-julia >n &#61; 144
V &#61; 80_000
i &#61; 0.03
p &#61; V*&#40;1&#43;i&#41;^n*i/&#40; &#40;1&#43;i&#41;^n - 1&#41;</code></pre><pre><code class=plaintext >2434.502443812203</code></pre>
<pre><code class=language-julia >n &#61; 48
i &#61; 0.1 / 100
V &#61; 40_000
p &#61; V*&#40;1&#43;i&#41;^n*i/&#40; &#40;1&#43;i&#41;^n - 1&#41;</code></pre><pre><code class=plaintext >853.9098445091832</code></pre>
<pre><code class=language-julia >n &#61; 48
V &#61; 40_000
p &#61; 900
#i &#61; ?</code></pre><pre><code class=plaintext >900</code></pre>
\[\begin{aligned}
\lim_{i \to 0} \frac{(1 + i)^n i}{(1 + i)^n - 1}
& = \lim_{y \to 1} \frac{y^n (y - 1)}{y^n - 1} \\
& = \lim_{y \to 1} \frac{y^{n+1} - y^n}{y^n - 1} \\
& = \lim_{y \to 1} \frac{(n+1)y^n - ny^{n-1}}{ny^{n-1}} \\
& = \frac{(n+1) - n}{n} \\
& = \frac{1}{n},
\end{aligned}\]
<p>onde a última igualdade do limite segue de L&#39;Hôpital. Daí, temos \(\displaystyle \lim_{i \to 0} p = \dfrac{V}{n}\). Então, uma maneira de deixar essa função contínua é definir</p>
\[ f(i) = \left\{\begin{array}{ll}
p - V \dfrac{(1+i)^n i}{(1+i)^n-1}, & i \neq 0, \\
p - \dfrac{V}{n}, & i = 0.
\end{array}\right.\]
<p>Vamos ver agora como resolver esse problema.</p>
<h1 id="método_da_bissecção"><a href="#método_da_bissecção" class=header-anchor >Método da bissecção</a></h1>
<p>O método da bissecção é um método bastante simples de se entender, de explicar, e de implementar, por isso é um dos favoritos.</p>
<p>A base do método é o Teorema do Valor Intermediário:</p>
<p><strong>Teorema do Valor Intermediário:</strong>Se \(f\) é contínua em \([a,b]\) e \(f(a)\) e \(f(b)\) têm sinais opostos, então existe \(c \in [a,b]\) tal que \(f(c) = 0\).</p>
<p>O método da bissecção simplesmente toma o intervalo \([a,b]\) e divide-o em dois, digamos \([a,c]\) e \([c,b]\). Caso tenhamos sorte, o ponto \(c\) será um zero da função \(f\), isto é, \(f(c) = 0\). Caso contrário, o sinal de \(f(c)\) será oposto à ou \(f(a)\), ou \(f(b)\). Desse modo, um dos intervalos \([a,c]\) ou \([c,b]\) terá um zero, pelo TVI. Logo, podemos repetir o processo.</p>
<p>Antes de considerar os detalhes de algum algoritmo que implemente o método da bissecção, vamos considerar a convergência do método, definido matematicamente. Para tanto, definimos a seguinte hipótese</p>
<ul>
<li><p><strong>H-B1:</strong> \(f\) é contínua em \([a,b]\), \(a < b\) e \(f(a)\) e \(f(b)\) têm sinais opostos.</p>

</ul>
<p>Podemos definir duas sequências para o método da bissecção: \(\{a_k\}\) e \(\{b_k\}\), onde \([a_0,b_0] = [a,b]\) é o intervalo inicial dado, e cada intervalo \([a_k,b_k]\) é gerado na iteração \(k\) do método, da seguinte maneira:</p>
<ul>
<li><p>Define-se \(x_k = \dfrac{a_{k-1} + b_{k-1}}{2}\);</p>

<li><p>Caso \(f(x_k) = 0\), define-se \(a_k = b_k = x_k\);</p>

<li><p>Caso contrário, se \(f(a_{k-1})\) e \(f(x_k)\) tenham sinais diferentes, define-se \(a_k = a_{k-1}\) e \(b_k = x_k\);</p>

<li><p>Caso nenhum dos casos anteriores aconteça, define-se \(a_k = x_k\) e \(b_k = b_{k-1}\).</p>

</ul>
<p>Vamos agora demonstrar que o intervalo \([a_k,b_k]\) vai se fechando ao redor de um zero de \(f\).</p>
<p><strong>Lema:</strong> Suponha que vale H-B1 e que \(a_k < b_k\), então \(f(a_k)\) e \(f(b_k)\) têm sinais opostos.</p>
<p><em>Dem.:</em> Primeiro, veja que \(x_j\) não é zero de \(f\) em nenhuma iteração \(j = 1,\dots,k\). Caso contrário, teríamos \(a_j = b_j = x_j = a_k = b_k\), que não é o caso. Agora, demonstramos o resultado por indução.</p>
<p>Se \(f(a)\) e \(f(x_1)\) têm sinais diferentes, então \(a_1 = a\) e \(b_1 = x_1\), e fica provado. Caso contrário, \(a_1 = x_1\) e \(b_1 = b\). Mas \(f(a)\) e \(f(x_1)\) têm sinais iguais, e \(f(b)\) e \(f(a)\) têm sinais opostos. Logo, \(f(x_1)\) e \(f(b)\) têm sinais opostos, e fica provado.</p>
<p>Suponha que vale para \(k-1\). No caso de \(f(a_{k-1})\) e \(f(x_k)\) terem sinais diferentes, então fica claro que \(f(a_k) = f(a_{k-1})\) e \(f(b_k) = f(x_k)\) têm sinais diferentes. Falta analisar o caso contrário. Temos que \(a_k = x_k\) e que \(b_k = b_{k-1}\), então temos que mostrar que \(f(x_k)\) e \(f(b_{k-1})\) têm sinais opostos. Mas como \(f(a_{k_1})\) e \(f(x_k)\) têm o mesmo sinal, e por hipótese de indução, temos \(f(a_{k-1})\) e \(f(b_{k-1})\) têm sinais opostos, então \(f(x_k)\) e \(f(b_{k-1})\) têm sinais opostos, e fica provado. \(\blacksquare\)</p>
<p>O Lema acima serve para mostrar que em cada iteração do método da bissecção, teremos as hipóteses do Teorema do Valor Intermediário satisfeitas. Agora vamos para o Teorema que diz que as sequências convergem.</p>
<p><strong>Teorema &#40;de convergência do método da bissecção&#41;:</strong> Sob a hipóteses H-B1, o método da bissecção gera sequências \(\{a_k\}\) e \(\{b_k\}\) convergentes, ambas para um mesmo valor \(c \in [a,b]\) com \(f(c) = 0\).</p>
<p><em>Dem.:</em> Primeiro, se existe alguma iteração onde \(x_k\) satisfaz \(f(x_k) = 0\), então \(a_k = b_k = x_k\) e depois disso, \(a_j = b_j = x_k\) para todo \(j > k\). Sendo assim, trivialmente essa sequência converge, para \(c \equiv x_k\).</p>
<p>Suponha agora que não existe \(x_k\) tal que \(f(x_k) = 0\). Note que</p>
\[a \leq a_1 \leq \dots \leq a_k \leq \dots \leq b_k \leq \dots \leq b_1 \leq b. \]
<p>Isso quer dizer que a sequência \(\{a_k\}\) é não decrescente e limitada superiormente. Portanto, é convergente. Por outro lado, a sequência \(\{b_k\}\) é não crescente e limitada inferiormente. Portanto, também é convergente. Não somente isso, mas pela definição de \(x_k\), temos</p>
\[ b_k - a_k = \dfrac{b_{k-1} - a_{k-1}}{2} = \dfrac{b - a}{2^k}, \]
<p>de modo que \(b_k - a_k \rightarrow 0\). Como \(b_k \rightarrow b^*\) e \(a_k \rightarrow a^*\), então \(b_k - a_k \rightarrow b^* - a^* = 0\). Portanto \(a^* = b^*\), isto é, ambas sequências convergem para um mesmo valor, que denotaremos de \(c\).</p>
<p>Para mostrar que \(f(c) = 0\), note que pela Lema anterior, como \(a_k < b_k\), temos que \(f(a_k)\) e \(f(b_k)\) têm sinais diferentes. Sendo assim, existe \(c_k \in (a_k,b_k)\) tal que \(f(c_k) = 0\). Como \(a_k < c_k < b_k\), pelo Teorema do Confronto, temos que \(c_k \rightarrow c\). Pela continuidade da função \(f\), temos que \(f(c_k) \rightarrow f(c)\), que implica em \(f(c) = 0\). \(\blacksquare\)</p>
<p>O pseudo-código para o método está abaixo.</p>
<p><strong>Entrada:</strong> \(f, a, b\) tais que \(f(a) * f(b) < 0\)</p>
<ol>
<li><p>\(x \leftarrow (a + b) / 2\)</p>

<li><p>Enquanto \(f(x) \neq 0\)</p>
<ol>
<li><p>Se \(f(a) * f(x) < 0\), faça \(b \leftarrow x\)</p>

<li><p>Senão, isto é, se \(f(b) * f(x) < 0\) \(a \leftarrow x\)</p>

<li><p>\(x \leftarrow (a + b) / 2\)</p>

</ol>

<li><p>Retorne \(x\)  Saída: \(x\) tal que \(f(x) = 0\)</p>

</ol>
<pre><code class=language-julia >a, b &#61; 1.0, 2.0
f&#40;x&#41; &#61; x^2 - 2</code></pre><pre><code class=plaintext >f (generic function with 1 method)</code></pre>
<pre><code class=language-julia >f&#40;a&#41; * f&#40;b&#41;</code></pre><pre><code class=plaintext >-2.0</code></pre>
<pre><code class=language-julia >a, b</code></pre><pre><code class=plaintext >(1.0, 2.0)</code></pre>
<pre><code class=language-julia >x &#61; &#40;a &#43; b&#41; / 2
if f&#40;a&#41; * f&#40;x&#41; &lt; 0
    b &#61; x
else
    a &#61; x
end
a, b</code></pre><pre><code class=plaintext >(1.0, 1.5)</code></pre>
<pre><code class=language-julia >x</code></pre><pre><code class=plaintext >1.5</code></pre>
<pre><code class=language-julia >f&#40;x&#41;</code></pre><pre><code class=plaintext >0.25</code></pre>
<pre><code class=language-julia >x^2</code></pre><pre><code class=plaintext >2.25</code></pre>
<pre><code class=language-julia >function bisseccao&#40;f, a, b; tol &#61; 1e-8&#41;
    fa &#61; f&#40;a&#41;
    x &#61; &#40;a &#43; b&#41; / 2
    fx &#61; f&#40;x&#41;
    while abs&#40;fx&#41; &gt; tol
        x &#61; &#40;a &#43; b&#41; / 2
        fx &#61; f&#40;x&#41;
        if fa * fx &lt; 0
            b &#61; x
        else
            a &#61; x
            fa &#61; fx
        end
    end
    return x, fx
end

bisseccao&#40;x -&gt; x^2 - 2, 1, 2&#41;</code></pre><pre><code class=plaintext >(1.4142135605216026, -5.236811428943611e-9)</code></pre>
<pre><code class=language-julia >bisseccao&#40;x -&gt; x^2 - 2, 1, 2, tol&#61;1e-4&#41;</code></pre><pre><code class=plaintext >(1.4141845703125, -8.200109004974365e-5)</code></pre>
<p>Note que chamados esse processo de <em>método</em> da bissecção, não de <em>algoritmo</em> de bissecção. Essa é uma diferença importante e recorrente. Aqui, a cerne do nosso estudo é o &quot;miolo&quot; do algoritmo, isto é, como definir algo matematicamente de modo que propriedades teóricas sejam satisfeitas. Em geral, as condições de parada não ficam bem estabelecidas num método. Além disso, existe a questão das <em>hipóteses de entrada</em>. Quando não são satisfeitas, um algoritmo deve lidar com isso, enquanto que o método é definido supondo tais hipóteses. Além das hipóteses de entrada, existem as <em>hipóteses de convergência</em>, que serão definidas posteriormente para mostrar que o método funciona. Algumas dessas hipóteses não podem ser testadas computacionalmente, por exemplo a continuidade da função \(f\). No entanto, essa hipótese é essencial para que o método funcione. Muitas vezes, as hipóteses de entrada e de convergência aparecem simplesmente como hipóteses. Computacionalmente, devemos adicionar critérios de parada adicionais para garantir a finitude do algoritmo. Isso foi visto, por exemplo, quando trabalhamos com a sequência de Collatz.</p>
<h2 id="critério_de_sucesso"><a href="#critério_de_sucesso" class=header-anchor >Critério de sucesso</a></h2>
<p>Uma questão importante neste método, e em muitos outros métodos matemáticos, é que \(f(x) = 0\) pode não acontecer em tempo finito, assim como pode não ser possível computacionalmente. Por exemplo, a sequência \(x_k = 1/k\) converge para \(0\), mas nunca chegará nela em tempo finito se cada iteração levar uma quantidade de tempo \(t \geq t_{\min} > 0\).</p>
<p>Por outro lado, veja o exemplo abaixo para a função</p>
\[ f(x) = \bigg(\cos(x) - \frac{1}{2}\bigg)^2, \]
<p>onde buscamos uma solução no intervalo \([0,\pi]\) &#40;que é \(\pi/3\)&#41;.</p>
<pre><code class=language-julia >f&#40;x&#41; &#61; &#40;cos&#40;x&#41; - 0.5&#41;^2
s &#61; pi/3
sn &#61; nextfloat&#40;s&#41;
sn2 &#61; nextfloat&#40;sn&#41;
sp &#61; prevfloat&#40;s&#41;

println&#40;&quot;Solução esperada: s &#61; π/3 &#61; &#36;s&quot;&#41;
println&#40;&quot;f&#40;s&#41; &#61; &#36;&#40;f&#40;s&#41;&#41;&quot;&#41;
println&#40;&quot;Próximo ponto flutuante: sn &#61; &#36;sn&quot;&#41;
println&#40;&quot;f&#40;sn&#41; &#61; &#36;&#40;f&#40;sn&#41;&#41;&quot;&#41;
println&#40;&quot;Próximo ponto flutuante: sn2 &#61; &#36;sn2&quot;&#41;
println&#40;&quot;f&#40;sn2&#41; &#61; &#36;&#40;f&#40;sn2&#41;&#41;&quot;&#41;
println&#40;&quot;Ponto flutuante antes de s: sp &#61; &#36;sp&quot;&#41;
println&#40;&quot;f&#40;sp&#41; &#61; &#36;&#40;f&#40;sp&#41;&#41;&quot;&#41;</code></pre><pre><code class=plaintext >Solução esperada: s = π/3 = 1.0471975511965976
f(s) = 1.232595164407831e-32
Próximo ponto flutuante: sn = 1.0471975511965979
f(sn) = 1.232595164407831e-32
Próximo ponto flutuante: sn2 = 1.047197551196598
f(sn2) = 7.703719777548943e-32
Ponto flutuante antes de s: sp = 1.0471975511965974
f(sp) = 1.1093356479670479e-31
</code></pre>
<p>Isso sem falar no problema de escalamento:</p>
<pre><code class=language-julia >f&#40;x&#41; &#61; 1e50 * &#40;cos&#40;x&#41; - 0.5&#41;^2
s &#61; pi/3
sn &#61; nextfloat&#40;s&#41;
sn2 &#61; nextfloat&#40;sn&#41;
sp &#61; prevfloat&#40;s&#41;

println&#40;&quot;Solução esperada: s &#61; π/3 &#61; &#36;s&quot;&#41;
println&#40;&quot;f&#40;s&#41; &#61; &#36;&#40;f&#40;s&#41;&#41;&quot;&#41;
println&#40;&quot;Próximo ponto flutuante: sn &#61; &#36;sn&quot;&#41;
println&#40;&quot;f&#40;sn&#41; &#61; &#36;&#40;f&#40;sn&#41;&#41;&quot;&#41;
println&#40;&quot;Próximo ponto flutuante: sn2 &#61; &#36;sn2&quot;&#41;
println&#40;&quot;f&#40;sn2&#41; &#61; &#36;&#40;f&#40;sn2&#41;&#41;&quot;&#41;
println&#40;&quot;Ponto flutuante antes de s: sp &#61; &#36;sp&quot;&#41;
println&#40;&quot;f&#40;sp&#41; &#61; &#36;&#40;f&#40;sp&#41;&#41;&quot;&#41;</code></pre><pre><code class=plaintext >Solução esperada: s = π/3 = 1.0471975511965976
f(s) = 1.232595164407831e18
Próximo ponto flutuante: sn = 1.0471975511965979
f(sn) = 1.232595164407831e18
Próximo ponto flutuante: sn2 = 1.047197551196598
f(sn2) = 7.703719777548944e18
Ponto flutuante antes de s: sp = 1.0471975511965974
f(sp) = 1.1093356479670479e19
</code></pre>
<p>Ambos os problemas podem ser resolvidos lembrando que estamos trabalhando com aproximações dos valores pela máquina, e que então devemos ter uma <strong>tolerância</strong> para o quão próximo de \(0\) aceitaremos que um valor esteja.</p>
<p>A maneira mais simples de tentar resolver esse problema é utilizar uma <strong>tolerância absoluta</strong> \(\epsilon_a > 0\): se \(|f(x)| \leq \epsilon_a\), então consideramos que \(x\) é uma boa aproximação para um zero da função. Como visto acima, no entanto, podemos ter \(f\) multiplicada por alguma constante muito grande, que acaba desnivelando completamente nosso teste. Uma maneira de tentar resolver esse problema é utilizar uma <strong>tolerância relativa</strong>, onde multiplicamos uma constante \(\epsilon_r > 0\) por algum valor de referência. O valor de referência ideal deve conseguir identificar a escala de \(f\) perto da solução. Uma maneira de fazer isso é utilizar algum valor de \(f(x_k)\) como referência. Como não temos nenhuma informação de quantas informações serão necessárias para se chegar perto da solução, podemos utilizar o primeiro valor de \(f\) como referência, isto é \(f(x_0)\). Dessa maneira, se \(|f(x)| \leq \epsilon_r |f(x_0)|\), então \(x\) é uma boa aproximação para um zero da função.</p>
<p>Nossos problemas não acabaram ainda: qual critério utilizar? O absoluto ou o relativo? No primeiro exemplo, qualquer um dos dois funcionaria começando numa distância razoável da solução &#40;o número de iterações pode ser diferente&#41;. No segundo exemplo, só o relativo funcionaria. No entanto, podemos ter um exemplo onde a tolerância relativa não funciona, mas a absoluta funcionaria.</p>
<pre><code class=language-julia >f&#40;x&#41; &#61; &#40;cos&#40;pi/3 &#43; 1e-50 * &#40;x - pi/3&#41;&#41; - 0.5&#41;^2
s &#61; pi/3
sn &#61; nextfloat&#40;s&#41;
sn2 &#61; nextfloat&#40;sn&#41;
sp &#61; prevfloat&#40;s&#41;

println&#40;&quot;Solução esperada: s &#61; π/3 &#61; &#36;s&quot;&#41;
println&#40;&quot;f&#40;s&#41; &#61; &#36;&#40;f&#40;s&#41;&#41;&quot;&#41;
println&#40;&quot;Próximo ponto flutuante: sn &#61; &#36;sn&quot;&#41;
println&#40;&quot;f&#40;sn&#41; &#61; &#36;&#40;f&#40;sn&#41;&#41;&quot;&#41;
println&#40;&quot;Próximo ponto flutuante: sn2 &#61; &#36;sn2&quot;&#41;
println&#40;&quot;f&#40;sn2&#41; &#61; &#36;&#40;f&#40;sn2&#41;&#41;&quot;&#41;
println&#40;&quot;Ponto flutuante antes de s: sp &#61; &#36;sp&quot;&#41;
println&#40;&quot;f&#40;sp&#41; &#61; &#36;&#40;f&#40;sp&#41;&#41;&quot;&#41;

println&#40;&quot;x₀ &#61; 0.0, f&#40;x₀&#41; &#61; &#36;&#40;f&#40;0.0&#41;&#41;&quot;&#41;</code></pre><pre><code class=plaintext >Solução esperada: s = π/3 = 1.0471975511965976
f(s) = 1.232595164407831e-32
Próximo ponto flutuante: sn = 1.0471975511965979
f(sn) = 1.232595164407831e-32
Próximo ponto flutuante: sn2 = 1.047197551196598
f(sn2) = 1.232595164407831e-32
Ponto flutuante antes de s: sp = 1.0471975511965974
f(sp) = 1.232595164407831e-32
x₀ = 0.0, f(x₀) = 1.232595164407831e-32
</code></pre>
<p>Uma maneira que está sendo utilizada com mais frequência é uma combinação das duas tolerâncias.</p>
\[ |f(x)| \leq \epsilon_a + \epsilon_r |f(x_0)|. \]
<p>Em geral, vamos considerar uma combinação das duas condições quando possível.</p>
<p>Os valores de \(\epsilon_a\) e \(\epsilon_r\) variam de acordo com a aplicação e a necessidade de aproximações mais precisas. Os valores mais comuns são da ordem de \(10^{-4}\), \(10^{-6}\) e \(10^{-8}\).</p>
<h2 id="critérios_de_parada_escape"><a href="#critérios_de_parada_escape" class=header-anchor >Critérios de parada / escape</a></h2>
<p>Além do critério acima, precisamos definir outros critérios para obter a finitude. Um ponto interessante em muitos métodos matemáticos é que</p>
<blockquote>
<p><em>Mesmo que a condição de parada de sucesso não seja satisfeita, a saída do programa ainda pode ser útil.</em></p>
</blockquote>
<p>Esse é um conceito importante em muitos problemas. Em particular, em alguns problemas de programação linear e inteira, uma solução precisa pode ser computacionalmente inviável &#40;anos para se obter&#41;. O comum nesses casos, é estabelecer limites para o tempo de execução, iterações, memória, etc., e utilizar a melhor solução obtida até então.</p>
<p>Alguns dos critérios de paradas mais utilizados:</p>
<ul>
<li><p>Progresso lento &#40;e.g., a distância entre \(x_k\) e \(x_{k-1}\) ficou muito pequena, \(b_k - a_k\) está muito pequeno, etc.&#41;;</p>

<li><p>Limite de tempo;</p>

<li><p>Limite de iterações;</p>

<li><p>Limite de algum outro gasto - principalmente avaliações de função;</p>

<li><p>Falha na satisfação de alguma hipótese.</p>

</ul>
<p>Antes de olhar a implementação abaixo, faça uma implementação bastante simples do método da bissecção. Teste com a função \(f(x) = xe^x - 1\) no intervalo \([0, 1]\).</p>
<pre><code class=language-julia >&quot;&quot;&quot;
    bisseccao&#40;f, a, b; atol&#61;1e-6, rtol&#61;1e-6, maxiter&#61;10_000&#41;

Calcula um zero para &#96;f&#96; no intervalo &#96;&#91;a,b&#93;&#96; utilizando o método da bissecção.
Se &#96;f&#40;a&#41; * f&#40;b&#41; &gt; 0&#96;, então retorna um erro.

Saída: &#96;xₖ, f&#40;xₖ&#41;, k&#96;

    xₖ    - aproximação para um zero de f
    f&#40;xₖ&#41; - f aplicada nessa aproximação
    k     - número de iterações
&quot;&quot;&quot;
function bisseccao&#40;f::Function, a::Real, b::Real; atol&#61;1e-6, rtol&#61;1e-6, maxiter&#61;10_000&#41;
    &#40;fa, fb&#41; &#61; &#40;f&#40;a&#41;, f&#40;b&#41;&#41;
    ϵ &#61; atol &#43; rtol * &#40;abs&#40;fa&#41; &#43; abs&#40;fb&#41;&#41; / 2
    if abs&#40;fa&#41; &lt;&#61; ϵ
        return a, fa, 0
    elseif abs&#40;fb&#41; &lt;&#61; ϵ
        return b, fb, 0
    elseif fa * fb &gt; 0
        error&#40;&quot;f&#40;a&#41; e f&#40;b&#41; devem ter sinais diferentes&quot;&#41;
    end
    x &#61; &#40;a &#43; b&#41; / 2
    fx &#61; f&#40;x&#41;
    iter &#61; 1

    funcionou &#61; abs&#40;fx&#41; ≤ ϵ
    explodiu &#61; iter &gt; maxiter

    #while &#33;&#40;abs&#40;fx&#41; &lt;&#61; ϵ || iter &gt; maxiter&#41;
    while &#33;&#40;funcionou || explodiu&#41;
    #while abs&#40;fx&#41; &gt; ϵ &amp;&amp; iter ≤ maxiter

        if fx * fa &lt; 0
            b, fb &#61; x, fx
        else
            a, fa &#61; x, fx
        end

        x &#61; &#40;a &#43; b&#41; / 2
        fx &#61; f&#40;x&#41;
        iter &#43;&#61; 1

        funcionou &#61; abs&#40;fx&#41; ≤ ϵ
        explodiu &#61; iter &gt; maxiter
    end

    return x, fx, iter
end</code></pre><pre><code class=plaintext >bisseccao</code></pre>
<pre><code class=language-julia >xtil, fx, iter &#61; bisseccao&#40;x-&gt;x^2 - 2, 1, 2&#41;</code></pre><pre><code class=plaintext >(1.4142131805419922, -1.0799813026096672e-6, 19)</code></pre>
<pre><code class=language-julia >xtil^2</code></pre><pre><code class=plaintext >1.9999989200186974</code></pre>
<pre><code class=language-julia >x &#61; sqrt&#40;2&#41;</code></pre><pre><code class=plaintext >1.4142135623730951</code></pre>
<pre><code class=language-julia >Erro &#61; x - xtil</code></pre><pre><code class=plaintext >3.818311029579746e-7</code></pre>
<pre><code class=language-julia >ErroAbs &#61; abs&#40;Erro&#41;</code></pre><pre><code class=plaintext >3.818311029579746e-7</code></pre>
<pre><code class=language-julia >ErroRel &#61; ErroAbs/x</code></pre><pre><code class=plaintext >2.6999536216952265e-7</code></pre>
<pre><code class=language-julia >xtil, fx, iter &#61; bisseccao&#40;x-&gt;x^2 - 2, 1, 2, atol&#61;1e-12, rtol&#61;1e-12&#41;</code></pre><pre><code class=plaintext >(1.4142135623733338, 6.754596881819452e-13, 38)</code></pre>
<pre><code class=language-julia >abs&#40;x-xtil&#41;/x</code></pre><pre><code class=plaintext >1.6878493930850582e-13</code></pre>
<pre><code class=language-julia >xtil, fx, iter &#61; bisseccao&#40;x-&gt;x^2, -1, 3&#41;</code></pre><pre><code class=plaintext >f(a) e f(b) devem ter sinais diferentes
</code></pre>
<pre><code class=language-julia >xtil, fx, iter &#61; bisseccao&#40;x-&gt;x*exp&#40;x&#41; - 1.0, 0, 1, atol&#61;1e-12, rtol&#61;1e-12&#41;</code></pre><pre><code class=plaintext >(0.5671432904091489, -1.7544854458151349e-12, 38)</code></pre>
<h3 id=exemplo_da_tabela_price ><a href="#exemplo_da_tabela_price" class=header-anchor >Exemplo da Tabela Price</a></h3>
<p>Exercício: Faça uma pequena função que recebe \(p\), \(V\) e \(n\) e calcula \(i\) correspondente da tabela price. Reveja a introdução do capítulo para pegar os significados das constantes. Para \(V = 10000\) e \(n = 10\), compare com os seguintes valores de \(p\):</p>
<ul>
<li><p>\(p = 1100\);</p>

<li><p>\(p = 1500\);</p>

<li><p>\(p = 1000\);</p>

<li><p>\(p = 990\).</p>

</ul>
<p>Compare sua solução com a <a href="https://www3.bcb.gov.br/CALCIDADAO/publico/calcularFinanciamentoPrestacoesFixas.do">Calculadora do Cidadão do Banco Central</a>.</p>
<p>Encontre alguma promoção online de venda de carros e compare o juros do anúncio com o juros calculado pela sua calculadora. Note que o valor de entrada é descontado de \(V\).</p>
<pre><code class=language-julia >function equacao_price&#40;i, p, V, n&#41;
    #Implemente
    if i &#61;&#61; 0
        return p - V / n
    else
        return p - V * i * &#40;1 &#43; i&#41;^n / &#40;&#40;1 &#43; i&#41;^n - 1&#41;
    end
end

function calc_juros&#40;p, V, n :: Int&#41;
    #Implemente
    if p &lt; 0 || V &lt; 0 || n &lt; 1 || p ≥ V
        error&#40;&quot;Não é possível&quot;&#41;
    end
    f&#40;i&#41; &#61; equacao_price&#40;i, p, V, n&#41;
    a &#61; -1.0
    b &#61; 1.0
    i, fi, k &#61; bisseccao&#40;f, a, b&#41;
    return i
end</code></pre><pre><code class=plaintext >calc_juros (generic function with 1 method)</code></pre>
<pre><code class=language-julia >equacao_price&#40;0.0346015, 120, 1000, 10&#41;</code></pre><pre><code class=plaintext >2.3004621965583283e-5</code></pre>
<pre><code class=language-julia >calc_juros&#40;120, 1000, 10&#41;</code></pre><pre><code class=plaintext >0.03460121154785156</code></pre>
<pre><code class=language-julia >calc_juros&#40;1100, 10_000, 10&#41;</code></pre><pre><code class=plaintext >0.0177154541015625</code></pre>
<pre><code class=language-julia >calc_juros&#40;1500, 10_000, 10&#41;</code></pre><pre><code class=plaintext >0.08144187927246094</code></pre>
<pre><code class=language-julia >calc_juros&#40;1000, 10_000, 10&#41;</code></pre><pre><code class=plaintext >0.0</code></pre>
<pre><code class=language-julia >calc_juros&#40;990, 10_000, 10&#41;</code></pre><pre><code class=plaintext >-0.00182342529296875</code></pre>
<pre><code class=language-julia >calc_juros&#40;-1.0, 10_000, 10&#41;</code></pre><pre><code class=plaintext >Não é possível
</code></pre>
<pre><code class=language-julia >calc_juros&#40;11000, 10_000, 10&#41;</code></pre><pre><code class=plaintext >Não é possível
</code></pre>
<h1 id="método_de_newton"><a href="#método_de_newton" class=header-anchor >Método de Newton</a></h1>
<p>Apesar do método da bissecção ser extremamente simples de se implementar, ele pode ser muito lento. Uma alternativa é utilizar o método de Newton. Esse método, com variações em diversas áreas, é um dos métodos mais famosos e importantes. Um professor costumava dizer:</p>
<blockquote>
<p><em>Se você criar alguma coisa e for tão bom quanto Newton, é porque você fez o Newton com alguma outra cara.</em></p>
</blockquote>
<p>Algumas ressalvas se aplicam na frase acima, mas Newton realmente é considerado um dos melhores métodos para vários problemas. Vamos estudar quando usar o Newton é bom, e quando ele pode falhar.</p>
<h2 id="métodos_geradores_de_passos"><a href="#métodos_geradores_de_passos" class=header-anchor >Métodos geradores de passos</a></h2>
<p>O método de Newton cai numa categoria de métodos chamada de &quot;geradores de passos&quot;. Um método gerador de passos começa com uma aproximação inicial \(x_0\) e define em cada iteração \(k\) define um passo \(d_k\) e calcula uma nova iteração fazendo </p>
\[x_k = x_{k-1} + d_k.\]
<p>Essa definição é bastante simples, mas é bastante importante numa consideração que não entraremos nesta disciplina: <strong>paralelismo</strong>. Se tivermos a possibilidade de realizar operações em paralelo e utilizamos um método gerador de passos, ficamos presos na paralelização da iteração \(k\). Outros métodos, por exemplo do tipo dividir e conquistar, podem paralelizar cada parte separada às vezes.</p>
<h3 id="motivação_do_método_de_newton"><a href="#motivação_do_método_de_newton" class=header-anchor >Motivação do Método de Newton</a></h3>
<p>O método de Newton tem duas motivações: <em>geométrica</em> e <em>teórica</em>. Ambas seguem da mesma ideia de aproximar a função \(f\) por uma função afim em torno da iteração atual.</p>
<p>Motivação geométrica</p>
<pre><code class=language-julia >using Plots
gr&#40;size&#61;&#40;600,400&#41;&#41;
f&#40;x&#41; &#61; x^2 - 2
plot&#40;f, 0, 3, c&#61;:blue, lab&#61;&quot;f&quot;, leg&#61;:topleft&#41;
plot&#33;&#40;x-&gt;0, 0, 3, c&#61;:black, lab&#61;&quot;&quot;&#41;
a &#61; 2.5
scatter&#33;&#40;&#91;a&#93;, &#91;f&#40;a&#41;&#93;, c&#61;:red, lab&#61;&quot;x0&quot;&#41;
L&#40;x&#41; &#61; f&#40;a&#41; &#43; 2 * a * &#40;x - a&#41;
plot&#33;&#40;L, 0, 3, c&#61;:red, lab&#61;&quot;L0&quot;&#41;
ylims&#33;&#40;-2, 5&#41;
png&#40;joinpath&#40;@OUTPUT, &quot;fig-zeros1&quot;&#41;&#41;</code></pre>

  <figure style="text-align: center">
   <img src="/calculo-numerico/assets/zeros-de-funcoes/code/output/fig-zeros1.png" alt=""> 
  </figure>
  
<p>Motivação geométrica</p>
<pre><code class=language-julia >f&#40;x&#41; &#61; x^2 - 2
plot&#40;f, 0, 3, c&#61;:blue, lab&#61;&quot;f&quot;, leg&#61;:topleft&#41;
plot&#33;&#40;x-&gt;0, 0, 3, c&#61;:black, lab&#61;&quot;&quot;&#41;
a &#61; 2.5
scatter&#33;&#40;&#91;a&#93;, &#91;f&#40;a&#41;&#93;, c&#61;:blue, lab&#61;&quot;x0&quot;&#41;
a &#61; a - f&#40;a&#41; / 2a
plot&#33;&#40;&#91;a; a&#93;, &#91;0; f&#40;a&#41;&#93;, l&#61;:dash, c&#61;:red, lab&#61;&quot;&quot;&#41;
scatter&#33;&#40;&#91;a&#93;, &#91;f&#40;a&#41;&#93;, c&#61;:red, lab&#61;&quot;x1&quot;&#41;
L&#40;x&#41; &#61; f&#40;a&#41; &#43; 2 * a * &#40;x - a&#41;
plot&#33;&#40;L, 0, 3, c&#61;:red, lab&#61;&quot;L1&quot;&#41;
ylims&#33;&#40;-2, 5&#41;
png&#40;joinpath&#40;@OUTPUT, &quot;fig-zeros2&quot;&#41;&#41;</code></pre>

  <figure style="text-align: center">
   <img src="/calculo-numerico/assets/zeros-de-funcoes/code/output/fig-zeros2.png" alt=""> 
  </figure>
  
<h4 id="a_motivação_é_bastante_simples_achar_o_zero_de_uma_função_afim_é_muito_mais_simples_que_de_uma_função_não_afim"><a href="#a_motivação_é_bastante_simples_achar_o_zero_de_uma_função_afim_é_muito_mais_simples_que_de_uma_função_não_afim" class=header-anchor >A motivação é bastante simples: achar o zero de uma função afim é muito mais simples que de uma função não afim.</a></h4>
<p>Então, vamos aproximar a função \(f\) por uma função afim na iteração \(k\) em torno do ponto \(x_{k-1}\), e chamar seu zero de \(x_k\). Repetimos o processo até que o critério de convergência seja satisfeito.</p>
<p>Teoricamente, estamos considerando a seguinte aproximação de Taylor:</p>
\[ f(x_{k-1} + d) = f(x_{k-1}) + df'(x_{k-1}) + \frac{d^2}{2}f''(\xi), \]
<p>onde \(d\) é o <strong>passo</strong> que estamos tomando, e \(\xi\) é um valor entre \(x_{k-1}\) e \(x_{k-1}+d\). A aproximação de primeira ordem de \(f\) é</p>
\[ L(d) = f(x_{k-1}) + df'(x_{k-1}), \]
<p>e a se \(d\) ou \(f''(\xi)\) forem muito próximos de zero, então o valor \(f(x_{k-1}+d) \approx L(d)\). Como queremos \(f(x_{k-1}+d_k) = 0\), definimos \(d_k\) a partir da solução de \(L(d_k) = 0\). Em outras palavras,</p>
\[ f(x_{k-1}) + d_kf'(x_{k-1}) = 0. \]
<p>Desse modo, se \(f'(x_{k-1} \neq 0\), temos</p>
\[d_k = -\dfrac{f(x_{k-1})}{f'(x_{k-1})}.\]
<p>Isso nos permite definir a sequência gerada pelo método de Newton por</p>
\[ x_k = x_{k-1} + d_k = x_{k-1} - \frac{f(x_{k-1})}{f'(x_{k-1})}. \]
<p>Em particular, muitas vezes é mais claro escrever para \(k+1\):</p>
\[ x_{k+1} = x_k - \frac{f(x_k)}{f'(x_k)}. \]
<p>Note que essa sequência só está bem definida se \(f'(x_k) \neq 0\) para todo \(k\). Além disso, não é trivial ver se essa sequência converge, diferente do que acontece com o método da bissecção. Por sorte, temos um teorema declarando esse resultado.</p>
<p><strong>Teorema &#40;da convergência do método de Newton&#41;:</strong> Se \(f\) é continuamente diferenciável no intervalo \([a,b]\) e existe \(c \in (a,b)\) tal que \(f(c) = 0\) e \(f'(c) \neq 0\), então existe \(\delta > 0\) tal que se \(x_0 \in [c-\delta,c+\delta]\), então o método de Newton começando por \(x_0\) gera uma sequência bem definida e convergente para \(c\). Se, além disso, \(f''\) for contínua numa vizinhança de \(c\), então a sequência converge quadraticamente.</p>
<p><em>Dem.:</em> A demonstração foge do escopo da disciplina. Existem vários livros que podem ser consultados para verificar esta demonstração. Em particular, Ruggiero e Lopes ou Burden e Faires contém essa demonstração. \(\blacksquare\).</p>
<p>É importante perceber a diferença fundamental entre este teorema e o teorema de convergência do método de bissecção. No teorema da bissecção, uma condição bastante simples de mudança de sinal precisa ser satisfeita. Aqui, o teorema diz apenas que existe uma vizinhança da solução onde podemos começar nosso método. Não é dito nada sobre o tamanho desse intervalo, e além disso, precisariamos saber do valor de \(c\) para saber onde centrar esse intervalo. Isso muda fortemente nosso uso do método. Já que não é possível saber se estamos satisfazendo as condições de convergência, teremos sempre a preocupação de que podemos falhar a qualquer momento. Logo, é imperativo que coloquemos condições de parada de exaustão para a finitude do método.</p>
<p>A parte sobre convergência quadrática será explicada abaixo.</p>
<p>As condições mais importantes aqui são:</p>
<ul>
<li><p>Condição de sucesso &#40;\(|f(x_k)| \leq \epsilon_a + \epsilon_r|f(x_0)|\).&#41;;</p>

<li><p>Exaustão de algum tipo &#40;avaliações de função, iterações, tempo&#41;;</p>

<li><p>Derivada nula &#40;ou muito próxima de zero&#41;.</p>

</ul>
<pre><code class=language-julia >using Printf

&quot;&quot;&quot;
    newton&#40;f, fder, x; atol&#61;1e-6, rtol&#61;1e-6, maxiter&#61;10_000, fdertol&#61;1e-12&#41;

Calcula um zero para a função &#96;f&#96; utilizando o método de Newton.
Inicia o método a partir do ponto &#96;x&#96; e usa a função &#96;fder &#96; como
derivada da função &#96;f&#96;.

Caso a derivada fique muito próxima de zero, um erro é lançado.

Saída: &#96;xₖ, f&#40;xₖ&#41;, k&#96;

    xₖ    - aproximação para um zero de f
    f&#40;xₖ&#41; - f aplicada nessa aproximação
    k     - número de iterações
&quot;&quot;&quot;
function newton&#40;f, fder, x; atol&#61;1e-6, rtol&#61;1e-6, maxiter&#61;30, fdertol&#61;1e-12&#41;
    fx &#61; f&#40;x&#41;
    iter &#61; 0
    ϵ &#61; atol &#43; rtol * abs&#40;fx&#41;
    while &#33;&#40;abs&#40;fx&#41; &lt;&#61; ϵ || iter &gt; maxiter&#41;
        fderx &#61; fder&#40;x&#41;
        if abs&#40;fderx&#41; &lt; fdertol
            error&#40;&quot;Derivada muito próxima de zero&quot;&#41;
        end
        @printf&#40;&quot;&#37;15.9e  &#37;8.2e\n&quot;, x, fx&#41;
        x &#61; x - fx/fderx
        fx &#61; f&#40;x&#41;
        iter &#43;&#61; 1
    end
    return x, fx, iter
end</code></pre><pre><code class=plaintext >newton</code></pre>
<pre><code class=language-julia >f&#40;x&#41; &#61; x^2 - 2
fder&#40;x&#41; &#61; 2x
x0 &#61; 1
x, fx, iter &#61; newton&#40;f, fder, x0, atol&#61;1e-12, rtol&#61;1e-12&#41;</code></pre><pre><code class=plaintext >1.000000000e+00  -1.00e+00
1.500000000e+00  2.50e-01
1.416666667e+00  6.94e-03
1.414215686e+00  6.01e-06
1.414213562e+00  4.51e-12
(1.4142135623730951, 4.440892098500626e-16, 5)</code></pre>
<pre><code class=language-julia >x, fx, iter &#61; newton&#40;f, fder, 100.0&#41;</code></pre><pre><code class=plaintext >1.000000000e+02  1.00e+04
5.001000000e+01  2.50e+03
2.502499600e+01  6.24e+02
1.255245805e+01  1.56e+02
6.355894695e+00  3.84e+01
3.335281609e+00  9.12e+00
1.967465562e+00  1.87e+00
1.492000890e+00  2.26e-01
(1.4162413320389438, 0.005739510575441642, 8)</code></pre>
<pre><code class=language-julia >x, fx, iter &#61; newton&#40;f, fder, 100.0, rtol&#61;0.0&#41;</code></pre><pre><code class=plaintext >1.000000000e+02  1.00e+04
5.001000000e+01  2.50e+03
2.502499600e+01  6.24e+02
1.255245805e+01  1.56e+02
6.355894695e+00  3.84e+01
3.335281609e+00  9.12e+00
1.967465562e+00  1.87e+00
1.492000890e+00  2.26e-01
1.416241332e+00  5.74e-03
1.414215014e+00  4.11e-06
(1.41421356237384, 2.107203300738547e-12, 10)</code></pre>
<pre><code class=language-julia >x, fx, iter &#61; newton&#40;x-&gt;x * exp&#40;x&#41; - 1, x-&gt;exp&#40;x&#41; * &#40;1 &#43; x&#41;, -1.0&#41;</code></pre><pre><code class=plaintext >Derivada muito próxima de zero
</code></pre>
<pre><code class=language-julia >x, fx, iter &#61; newton&#40;x-&gt;x * exp&#40;x&#41; - 1, x-&gt;exp&#40;x&#41; * &#40;1 &#43; x&#41;, 1.0&#41;</code></pre><pre><code class=plaintext >1.000000000e+00  1.72e+00
6.839397206e-01  3.55e-01
5.774544772e-01  2.87e-02
5.672297377e-01  2.39e-04
(0.5671432965302959, 1.6912338640651114e-8, 4)</code></pre>
<pre><code class=language-julia >x, fx, iter &#61; newton&#40;x-&gt;exp&#40;x&#41;, x-&gt;exp&#40;x&#41;, 1.0&#41;</code></pre><pre><code class=plaintext >1.000000000e+00  2.72e+00
0.000000000e+00  1.00e+00
-1.000000000e+00  3.68e-01
-2.000000000e+00  1.35e-01
-3.000000000e+00  4.98e-02
-4.000000000e+00  1.83e-02
-5.000000000e+00  6.74e-03
-6.000000000e+00  2.48e-03
-7.000000000e+00  9.12e-04
-8.000000000e+00  3.35e-04
-9.000000000e+00  1.23e-04
-1.000000000e+01  4.54e-05
-1.100000000e+01  1.67e-05
-1.200000000e+01  6.14e-06
(-13.0, 2.2603294069810542e-6, 14)</code></pre>
<pre><code class=language-julia >x, fx, iter &#61; newton&#40;x-&gt;x^2 &#43; 1, x-&gt;2x, 2.0&#41;</code></pre><pre><code class=plaintext >2.000000000e+00  5.00e+00
7.500000000e-01  1.56e+00
-2.916666667e-01  1.09e+00
1.568452381e+00  3.46e+00
4.654406117e-01  1.22e+00
-8.415306026e-01  1.71e+00
1.733901559e-01  1.03e+00
-2.796974974e+00  8.82e+00
-1.219722927e+00  2.49e+00
-1.999322995e-01  1.04e+00
2.400880393e+00  6.76e+00
9.921832581e-01  1.98e+00
-7.847533360e-03  1.00e+00
6.371036416e+01  4.06e+03
3.184733406e+01  1.02e+03
1.590796713e+01  2.54e+02
7.922552774e+00  6.38e+01
3.898165416e+00  1.62e+01
1.820817243e+00  4.32e+00
6.358066524e-01  1.40e+00
-4.684992666e-01  1.22e+00
8.329878964e-01  1.69e+00
-1.837548695e-01  1.03e+00
2.629138892e+00  7.91e+00
1.124393110e+00  2.26e+00
1.175122224e-01  1.01e+00
-4.196120445e+00  1.86e+01
-1.978902537e+00  4.92e+00
-7.367859702e-01  1.54e+00
3.102301433e-01  1.10e+00
-1.456591627e+00  3.12e+00
(-0.3850287022397705, 1.148247101548442, 31)</code></pre>
<pre><code class=language-julia >x, fx, iter &#61; newton&#40;x-&gt;x^2 &#43; 1e-8, x-&gt;2x, 2.0&#41;</code></pre><pre><code class=plaintext >2.000000000e+00  4.00e+00
9.999999975e-01  1.00e+00
4.999999938e-01  2.50e-01
2.499999869e-01  6.25e-02
1.249999734e-01  1.56e-02
6.249994672e-02  3.91e-03
3.124989336e-02  9.77e-04
1.562478668e-02  2.44e-04
7.812073335e-03  6.10e-05
3.905396633e-03  1.53e-05
(0.0019514180366262588, 3.818032353670283e-6, 10)</code></pre>
<p>O exemplo abaixo serve para mostrar que às vezes Newton não converge, nem explode, e sua derivada também não fica próxima de zero.</p>
<pre><code class=language-julia >a &#61; 1/sqrt&#40;5&#41;
println&#40;&quot;1/√5 &#61; &#36;a&quot;&#41;
x, fx, iter &#61; newton&#40;x-&gt;x^3 - x, x-&gt;3x^2 - 1, 1/sqrt&#40;5&#41;&#41;
println&#40;&quot;x &#61; &#36;x, iter &#61; &#36;iter&quot;&#41;</code></pre><pre><code class=plaintext >1/√5 = 0.4472135954999579
4.472135955e-01  -3.58e-01
-4.472135955e-01  3.58e-01
4.472135955e-01  -3.58e-01
-4.472135955e-01  3.58e-01
4.472135955e-01  -3.58e-01
-4.472135955e-01  3.58e-01
4.472135955e-01  -3.58e-01
-4.472135955e-01  3.58e-01
4.472135955e-01  -3.58e-01
-4.472135955e-01  3.58e-01
4.472135955e-01  -3.58e-01
-4.472135955e-01  3.58e-01
4.472135955e-01  -3.58e-01
-4.472135955e-01  3.58e-01
4.472135955e-01  -3.58e-01
-4.472135955e-01  3.58e-01
4.472135955e-01  -3.58e-01
-4.472135955e-01  3.58e-01
4.472135955e-01  -3.58e-01
-4.472135955e-01  3.58e-01
4.472135955e-01  -3.58e-01
-4.472135955e-01  3.58e-01
4.472135955e-01  -3.58e-01
-4.472135955e-01  3.58e-01
4.472135955e-01  -3.58e-01
-4.472135955e-01  3.58e-01
4.472135955e-01  -3.58e-01
-4.472135955e-01  3.58e-01
4.472135955e-01  -3.58e-01
-4.472135955e-01  3.58e-01
4.472135955e-01  -3.58e-01
x = -0.4472135954999579, iter = 31
</code></pre>
<p>Perceba que às vezes o método de Newton não funciona, mas quando funciona, tende a ser bem mais rápido que o método da bissecção. Isso se deve à parte do Teorema que diz que a <strong>convergência do método é quadrática</strong>.</p>
<p><strong>Def.:</strong> Uma sequência \(\{x_k\}\) convergente à \(a\) é dita ter convergência linear, ou quadrática, se</p>
\[ \lim_{k\to\infty} \frac{|x^{k+1} - a|}{|x^k - a|} = C, \]
<p>para algum \(0 < C < 1\), ou</p>
\[ \lim_{k\to\infty} \frac{|x^{k+1} - a|}{|x^k - a|^2} > 0, \]
<p>respectivamente.</p>
<p><strong>Def.:</strong> Uma sequência \(\{x_k\}\) convergente à \(a\) é dita ter convergência superlinear se</p>
\[ \frac{|x^{k+1} - a|}{|x^k - a|} = C_k, \]
<p>e \(C_k \to 0\) ou</p>
\[ \lim_{k\to\infty} \frac{|x^{k+1} - a|}{|x^k - a|} = 0. \]
<pre><code class=language-julia >using Printf

f&#40;x&#41; &#61; x^2 - 1.0
fder&#40;x&#41; &#61; 2x
x &#61; 10.0
k &#61; 0
@printf&#40;&quot;&#37;2s  &#37;11s  &#37;11s\n&quot;, &quot;k&quot;, &quot;f&#40;x&#41;&quot;, &quot;x_k - 1.0&quot;&#41;
@printf&#40;&quot;&#37;-2d  &#37;&#43;10.4e  &#37;&#43;10.4e\n&quot;, k, f&#40;x&#41;, x - 1.0&#41;
while abs&#40;f&#40;x&#41;&#41; &gt; 1e-12
    x &#61; x - f&#40;x&#41;/fder&#40;x&#41;
    k &#43;&#61; 1
    @printf&#40;&quot;&#37;-2d  &#37;&#43;10.4e  &#37;&#43;10.4e\n&quot;, k, f&#40;x&#41;, x - 1.0&#41;
end</code></pre><pre><code class=plaintext > k         f(x)    x_k - 1.0
0   +9.9000e+01  +9.0000e+00
UndefVarError: k not defined
</code></pre>
<p>Veja um exemplo onde as condições do Teorema não são verificadas.</p>
<pre><code class=language-julia >f&#40;x&#41; &#61; &#40;x - 1.0&#41;^2
fder&#40;x&#41; &#61; 2&#40;x - 1.0&#41;
x &#61; 10.0
k &#61; 0
@printf&#40;&quot;&#37;2s  &#37;11s  &#37;11s\n&quot;, &quot;k&quot;, &quot;f&#40;x&#41;&quot;, &quot;x_k - 1.0&quot;&#41;
@printf&#40;&quot;&#37;-2d  &#37;&#43;10.4e  &#37;&#43;10.4e\n&quot;, k, f&#40;x&#41;, x - 1.0&#41;
while abs&#40;f&#40;x&#41;&#41; &gt; 1e-12
    x &#61; x - f&#40;x&#41;/fder&#40;x&#41;
    k &#43;&#61; 1
    @printf&#40;&quot;&#37;-2d  &#37;&#43;10.4e  &#37;&#43;10.4e\n&quot;, k, f&#40;x&#41;, x - 1.0&#41;
end</code></pre><pre><code class=plaintext > k         f(x)    x_k - 1.0
0   +8.1000e+01  +9.0000e+00
UndefVarError: k not defined
</code></pre>
<pre><code class=language-julia >newton&#40;x -&gt; exp&#40;-x&#41; * x - 1, x -&gt; exp&#40;-x&#41; * &#40;-x &#43; 1&#41;, 1.0, atol&#61;1e-12, rtol&#61;0.0&#41;</code></pre><pre><code class=plaintext >Derivada muito próxima de zero
</code></pre>
<h2 id="aproximações_lineares_diferentes_de_newton"><a href="#aproximações_lineares_diferentes_de_newton" class=header-anchor >Aproximações lineares diferentes de Newton</a></h2>
<p>O Método de Newton tem uma grande falha. Se a derivada \(f'(x_k) = 0\), então a iteração \(k\) não está bem definida. No entanto, podemos aproximar essa derivada de algumas maneiras simples. Uma delas é utilizando dois pontos anteriores da curva:</p>
\[ m = \frac{f(x_k) - f(x_{k-1})}{x_{k} - x_{k-1}}. \]
<p>Essa aproximação forma, no lugar de uma reta tangente, uma reta <strong>secante</strong> à curva, de modo que chamamos o método que usa essa reta de <strong>Método Secante</strong>, ou da Secante.</p>
<p>Note que esse método precisa de um ponto inicial além do \(x_0\).</p>
<ol>
<li><p><strong>Entrada</strong>:</p>
<ul>
<li><p>\(f\): função real</p>

<li><p>\(x_0\): ponto inicial</p>

<li><p>\(x_1\): outra aproximação diferente de \(x_0\)</p>

</ul>

<li><p>k &#61; 1</p>

<li><p>Enquanto \(|f(x_k)| > ϵ\)</p>
<ol>
<li><p>\(m = \dfrac{f(x_k) - f(x_{k-1})}{x_k - x_{k-1}}\)</p>

<li><p>\(x_{k+1} = x_k - \dfrac{f(x_k)}{m}\)     #Obs: Essa conta pode ser aberta</p>

<li><p>Incremente \(k\)</p>

</ol>

<li><p>Saída:</p>
<ul>
<li><p>\(x_k\): aproximação para o zero de \(f\)</p>

<li><p>\(k\):  número de iterações.</p>

</ul>

</ol>
<pre><code class=language-julia >function secante&#40;f, a, b; atol &#61; 1e-6, rtol &#61; 1e-6, maxiter &#61; 30, fdertol &#61; 1e-6, xtol &#61; 1e-6&#41;
    #Exercício
    x &#61; b
    xold &#61; a
    fx &#61; f&#40;x&#41;
    fold &#61; f&#40;xold&#41;
    iter &#61; 0
    ϵ &#61; atol &#43; rtol * abs&#40;fx&#41;
    while &#33;&#40;abs&#40;fx&#41; &lt;&#61; ϵ || iter &gt; maxiter&#41;
        m &#61; &#40;fx - fold&#41; / &#40;x - xold&#41;
        if abs&#40;m&#41; &lt; fdertol
            error&#40;&quot;Inclinação muito próxima de zero&quot;&#41;
        end
        @printf&#40;&quot;&#37;15.9e  &#37;8.2e\n&quot;, x, fx&#41;
        xold, fold &#61; x, fx
        x &#61; x - fx/m
        if abs&#40;x - xold&#41; &lt; xtol
            error&#40;&quot;Passo muito pequeno&quot;&#41;
        end
        fx &#61; f&#40;x&#41;
        iter &#43;&#61; 1
    end
    return x, fx, iter
end

secante&#40;x-&gt;x^2 - 2, 0, 1&#41;</code></pre><pre><code class=plaintext >1.000000000e+00  -1.00e+00
2.000000000e+00  2.00e+00
1.333333333e+00  -2.22e-01
1.400000000e+00  -4.00e-02
1.414634146e+00  1.19e-03
1.414211438e+00  -6.01e-06
(1.4142135620573204, -8.931455575122982e-10, 6)</code></pre>
<pre><code class=language-julia >secante&#40;x-&gt;exp&#40;-x&#41; - x, 0, 1&#41;</code></pre><pre><code class=plaintext >1.000000000e+00  -6.32e-01
6.126998368e-01  -7.08e-02
5.638383892e-01  5.18e-03
5.671703584e-01  -4.24e-05
(0.5671433066049633, -2.5380166635002865e-8, 4)</code></pre>
<pre><code class=language-julia >secante&#40;x -&gt; x * exp&#40;x&#41; - 1, -1.0, -0.9&#41;</code></pre><pre><code class=plaintext >-9.000000000e-01  -1.37e+00
6.855033665e+01  4.05e+31
-9.000000000e-01  -1.37e+00
Passo muito pequeno
</code></pre>
<p>Outra modificação bastante simples, é o <strong>Método de Newton Modificado</strong>, que consiste de usar \(m\) fixo igual ao primeiro ponto \(f'(x_0)\). Na prática, após \(N\) iterações, esse valor é atualizado, de modo que o método fica como</p>
\[ x_{k+1} = x_k - \frac{f(x_k)}{m_k}, \]
<p>onde</p>
\[ m_k = \left\{\begin{array}{ll}
f'(x_k), \text{se } k \text{ é divisível por } N, \\
m_{k-1}, \text{caso contrário}.
\end{array}\right. \]
<pre><code class=language-julia >using ForwardDiff

f&#40;x&#41; &#61; exp&#40;x&#41; * x - 1
g&#40;x&#41; &#61; ForwardDiff.derivative&#40;f, x&#41;</code></pre><pre><code class=plaintext >g (generic function with 1 method)</code></pre>
<pre><code class=language-julia >&#40;f&#40;2 &#43; 1e-8&#41; - f&#40;2&#41;&#41; / 1e-8 - exp&#40;2&#41; * 3</code></pre><pre><code class=plaintext >-1.068681356741763e-7</code></pre>
<pre><code class=language-julia >g&#40;2&#41; - exp&#40;2&#41; * 3</code></pre><pre><code class=plaintext >0.0</code></pre>
<pre><code class=language-julia >f&#40;x&#41; &#61; begin
    println&#40;&quot;f em &#36;x&quot;&#41;
    return exp&#40;x&#41; * x
end
f&#40;2&#41;</code></pre><pre><code class=plaintext >f em 2
14.7781121978613</code></pre>
<pre><code class=language-julia >g&#40;x&#41; &#61; ForwardDiff.derivative&#40;f, x&#41;
g&#40;2&#41;</code></pre><pre><code class=plaintext >f em Dual{ForwardDiff.Tag{typeof(Main.FD_SANDBOX_11958563991374305944.f), Int64}}(2,1)
22.16716829679195</code></pre>
<h1 id="exercícios"><a href="#exercícios" class=header-anchor >Exercícios</a></h1>
<p>Faça os exercícios do capítulo 2, com exceção daqueles de assuntos não vistos em classe &#40;e.g. Método do Ponto Fixo&#41;.</p>
<ol>
<li><p>Utilize os métodos da Bissecção, de Newton e da Secante para encontrar uma</p>

</ol>
<p>aproximação para algum zero de cada uma das funções abaixo.  Para bissecção, use   o intervalo \([a,b]\) dado, para Newton use \(x_0 = a\), e para Secante, use \(x_0 = a\) e \(x_1 = b\).  Caso encontre alguma divisão por 0, raiz negativa, ou outro problema   de domínio, declare falha. Declare convergência com \(|f(x_k)| < 10^{-2}\).   <strong>Faça na mão</strong></p>
<ul>
<li><p>\(f(x) = x^2 - 2\), em \([1,2]\);</p>

<li><p>\(f(x) = e^{-x} - x\), em \([0,1]\);</p>

<li><p>\(f(x) = x^3 - 3x\), em \([1,2]\);</p>

<li><p>\(f(x) = x^3 - 3x\), em \([-1,1]\);</p>

<li><p>\(f(x) = \cos(x)\), em \([0,2]\);</p>

<li><p>\(f(x) = \dfrac{x}{x^2 - 4}\), em \([-1,1]\);</p>

</ul>
<ol start=2 >
<li><p>Faça o que se pede</p>

</ol>
<ul>
<li><p>Mostre que o método da bissecção aplicado à função \(f(x) = x - 2^{-n}\) leva \(n\) iterações para convergir &#40;teoricamente&#41;.</p>

<li><p>O exemplo em &#40;a&#41; mostra um defeito do método da bissecção: Ele pode demorar mesmo para funções fáceis. Para tentar remediar isso, o Método da Falsa Posição foi criado, onde a divisão do intervalo &#91;a,b&#93; é feita num ponto ponderado pelos valores dos inversos de \(|f(a)|\) e \(|f(b)|\). Desse modo, um ponto com valor de função mais próximo de zero tem peso maior. Em outras palavras, o próximo extremo do intervalo é dado por</p>

</ul>
\[ x = \frac{ap_1 + bp_2}{p_1 + p_2} \]
<p>onde \(p_1 = \dfrac{1}{|f(a)|}\) e \(p_2 = \dfrac{1}{|f(b)|}\).
Implemente este método.</p>
<ul>
<li><p>Mostre que o x do Método da Falsa Posição pode ser escrito como</p>

</ul>
\[ x = \frac{a f(b) - b f(a)}{f(b) - f(a)}. \]
<ul>
<li><p>Mostre que o Método da False Posição converge em uma iteração para qualquer função afim. Verifique isso para a função do item &#40;a&#41;.</p>

</ul>
<ol start=3 >
<li><p>Considere o Método de Newton aplicado à função \(f(x) = x^2 - 1\), a partir de algum \(x_0 > 0\). Mostre que</p>

</ol>
<ul>
<li><p>Se \(0 < x_0 < 1\), então \(x_1 > 1\). &#40;Dica: Use o fato de que \((x_0 - 1)^2 > 0\). &#41;</p>

<li><p>Se \(x_k > 1\), então \(x_{k+1} > 1\).</p>

<li><p>Se \(x_k > 1\), então \(x_{k+1} < x_k\).</p>

<li><p>Se \(x_0 > 0\), então \(x_k \to 1\).</p>

<li><p>Se \(x_k > 1\), então \(|x_{k+1} - 1| < |x_k - 1|^2/2\), logo \(x_k\) converge quadraticamente.</p>

<li><p>Se \(x_k > 1\), então \(|f(x_{k+1})| < |f(x_k)|^2 / 4\), logo \(f(x_k)\) converge quadraticamente.</p>

</ul>

</div>
</div>
</div>

<footer>
<div class="container-fluid text-center social-footer">
    <a href="mailto:abel.s.siqueira@gmail.com">
        <i class="fas fa-2x fa-envelope" aria-hidden=true ></i>
    </a><a href="https://github.com/abelsiqueira">
        <i class="fab fa-2x fa-github-square" aria-hidden=true ></i>
    </a><a href="https://linkedin.com/in/abel-siqueira/">
        <i class="fab fa-2x fa-linkedin" aria-hidden=true ></i>
    </a><a href="https://twitter.com/abel_siqueira">
        <i class="fab fa-2x fa-twitter-square" aria-hidden=true ></i>
    </a><a href="https://www.researchgate.net/profile/Abel_Siqueira">
        <i class="fab fa-2x fa-researchgate" aria-hidden=true ></i>
    </a><a href="http://orcid.org/0000-0003-4451-281X">
        <i class="fab fa-2x fa-orcid" aria-hidden=true ></i>
    </a>
</div>
</footer>


<script src="/calculo-numerico/libs/katex/katex.min.js"></script>
<script src="/calculo-numerico/libs/katex/auto-render.min.js"></script>
<script>renderMathInElement(document.body)</script>



<script src="/calculo-numerico/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>


<script src="/calculo-numerico/libs/bootstrap.bundle.min.js" crossorigin=anonymous ></script>
<script src="https://kit.fontawesome.com/d17d5e5245.js" crossorigin=anonymous ></script>
<script type="text/javascript" src="https://cdn.rawgit.com/pcooksey/bibtex-js/ef59e62c/src/bibtex_js.js"></script>