<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/calculo-numerico/libs/katex/katex.min.css"> <link rel=stylesheet  href="/calculo-numerico/libs/highlight/github.min.css"> <link href="/calculo-numerico/css/bootstrap.min.css" rel=stylesheet  crossorigin=anonymous > <link href="https://fonts.googleapis.com/css2?family=Cinzel&family=Lato&family=Montserrat&display=swap" rel=stylesheet > <link rel=icon  href="/calculo-numerico/assets/favicon.png"> <link rel=stylesheet  href="/calculo-numerico/css/code-katex.css"> <link rel=stylesheet  href="/calculo-numerico/css/custom.css"> <link rel=stylesheet  href="/calculo-numerico/css/dark-mode.css"> <title>Eliminação Gaussiana</title> <header> <nav class="navbar navbar-expand-lg"> <div class=container-fluid > <a class="navbar-brand text-end" href="/calculo-numerico/">Abel S.<br>Siqueira</a> <button class=navbar-toggler  type=button  data-bs-toggle=collapse  data-bs-target="#navbarSupportedContent" aria-controls=navbarSupportedContent  aria-expanded=false  aria-label="Toggle navigation"> <span class=navbar-toggler-icon ></span> </button> <div class="collapse navbar-collapse" id=navbarSupportedContent > <ul class="navbar-nav ms-auto mb-2 mb-lg-0"> <li class=nav-item ><a class=nav-link  href="/calculo-numerico/">Home</a> <li class=nav-item ><a class=nav-link  href="/calculo-numerico/julia/">Julia</a> <li class=nav-item ><a class=nav-link  href="/calculo-numerico/research/">Research</a> <li class=nav-item ><a class=nav-link  href="/calculo-numerico/ufpr/">UFPR</a> </ul> <div class="dark-switch form-check form-switch"> <input type=checkbox  class=form-check-input  id=darkSwitch  /> <label class=custom-control-label  for=darkSwitch >Dark Mode</label> </div> <script src="/calculo-numerico/libs/dark-mode-switch.min.js"></script> </div> </div> </nav> </header> <div class=container-fluid > <div class="container main-text"> <div class=franklin-content ><h1 id=matrizes ><a href="#matrizes" class=header-anchor >Matrizes</a></h1> <p>Matrizes são maneiras eficientes de representação de várias coisas, em especial transformações lineares. Muitas aplicações práticas caem em sistemas lineares, e mais outras têm representações matriciais. Sendo assim, a execução eficiente da chamada <strong>álgebra linear numérica</strong> é essencial.</p> <h2 id=blas ><a href="#blas" class=header-anchor >BLAS</a></h2> <p><strong>BLAS - Basic Linear Algebra Subroutines</strong>, corresponde à uma classe de softwares que implementam álgebra linear numérica. Existem diversos BLAS, sendo alguns proprietários, alguns abertos, alguns genéricos, e alguns específicos para o processador. O BLAS é uma das unidades mais básicas do software matemático, e não vamos tentar reimplementá-lo. Porém, vamos estudar alguns aspectos que são a base para coisas mais avançadas.</p> <pre><code class=language-julia >A &#61; rand&#40;3,3&#41;
v &#61; rand&#40;3&#41;
A * v</code></pre><pre><code class=plaintext >3-element Vector{Float64}:
 0.6063311281180966
 1.3074334601811501
 0.6045143479640743</code></pre> <pre><code class=language-julia >using LinearAlgebra

names&#40;LinearAlgebra.BLAS&#41; |&gt; show</code></pre><pre><code class=plaintext >[:BLAS, :asum, :axpby!, :axpy!, :blascopy!, :dotc, :dotu, :gbmv, :gbmv!, :gemm, :gemm!, :gemv, :gemv!, :ger!, :hemm, :hemm!, :hemv, :hemv!, :her!, :her2k, :her2k!, :herk, :herk!, :hpmv!, :iamax, :nrm2, :rot!, :sbmv, :sbmv!, :scal, :scal!, :spmv!, :symm, :symm!, :symv, :symv!, :syr!, :syr2k, :syr2k!, :syrk, :syrk!, :trmm, :trmm!, :trmv, :trmv!, :trsm, :trsm!, :trsv, :trsv!]</code></pre>
<p>As operações são classificas em ordens diferentes, de acordo com o número de operações. Alguns exemplos:</p>
<ul>
<li><p>Nível 1: \(\alpha x + y\), \(x^Ty\);</p>

<li><p>Nível 2: \(Ax\), \(L^{-1}b\) e \(U^{-1}b\), onde \(L\) e \(U\) são matrizes triangulares inferior e superior, resp.;</p>

<li><p>Nível 3: \(AB\) e algumas maneiras de resolver sistemas lineares.</p>

</ul>
<h3 id=alpha_x_y ><a href="#alpha_x_y" class=header-anchor >\(\alpha x + y\)</a></h3>
<p>Sendo \(z = \alpha x + y\), temos \(z_i = \alpha x_i + y_i\), então fazemos \(n\) multiplicações e \(n\) somas: \(2n\) operações.</p>
<h3 id=xty ><a href="#xty" class=header-anchor >\(x^Ty\)</a></h3>
<p>\(x^Ty = x_1y_1 + \dots + x_ny_n\), logo são \(n\) multiplicações e \(n-1\) somas: \(2n - 1\) operações.</p>
<h3 id=ax ><a href="#ax" class=header-anchor >Ax</a></h3>
<p>Sendo \(y = Ax\), com \(A \in \mathbb{R}^{m \times n}\), temos</p>
\[ y_i = \sum_{j = 1}^n a_{ij} x_j, \quad i = 1,\dots,m. \]
<p>Logo, são \(mn\) multiplicações e \((n-1)m\) somas: \(2mn - m\) operações.</p>
<h3 id=ab ><a href="#ab" class=header-anchor >AB</a></h3>
<p>Sendo \(C = AB\), com \(A \in \mathbb{R}^{m \times p}\) e \(B \in \mathbb{R}^{p \times n}\), temos</p>
\[ c_{ij} = \sum_{k = 1}^p a_{ik} b_{kj}, \qquad i = 1,\dots,m,\quad j = 1,\dots,n. \]
<p>Logo, são \(mnp\) multiplicações e \((p-1)mn\) somas: \(2mnp - mn\) operações.</p>
<h2 id=armazenamento ><a href="#armazenamento" class=header-anchor >Armazenamento</a></h2>
<p>Existe um conceito de matriz <strong>densa</strong> e <strong>esparsa</strong>. Quando uma matriz tem muitos zeros, ela é dita esparsa &#40;é um conceito <em>fuzzy</em>&#41;. Para matrizes realmente grandes, armazenar todos os elementos, inclusive os nulos, é inviável, ou até impossível.</p>
<p>O armazenamento de matrizes densas em geral é feito como um vetor linearizado. Isto é, espaços contíguos na memória. Isso é feito para minimizar o <em>seek</em>, i.e., a busca na memória. Isso quer dizer também que <strong>faz diferença como a matriz é percorrida.</strong></p>
<pre><code class=language-julia >using LinearAlgebra

function multAx1&#40;y, A, x&#41;
    m, n &#61; size&#40;A&#41;
    for i &#61; 1:m
        y&#91;i&#93; &#61; 0.0
        for j &#61; 1:n
            y&#91;i&#93; &#43;&#61; A&#91;i,j&#93; * x&#91;j&#93;
        end
    end
end

function multAx2&#40;y, A, x&#41;
    m, n &#61; size&#40;A&#41;
    for i &#61; 1:m
        y&#91;i&#93; &#61; 0.0
    end
    for j &#61; 1:n
        for i &#61; 1:m
            y&#91;i&#93; &#43;&#61; A&#91;i,j&#93; * x&#91;j&#93;
        end
    end
end

n &#61; 1000
A &#61; rand&#40;n, n&#41;
x &#61; rand&#40;n&#41;
y &#61; zeros&#40;n&#41;;

y1 &#61; zeros&#40;n&#41;
y2 &#61; zeros&#40;n&#41;
multAx1&#40;y1, A, x&#41;
multAx2&#40;y2, A, x&#41;
norm&#40;y1 - y2&#41;</code></pre><pre><code class=plaintext >0.0</code></pre>
<pre><code class=language-julia >t₀ &#61; time&#40;&#41;
multAx1&#40;y, A, x&#41;
Δt &#61; time&#40;&#41; - t₀</code></pre><pre><code class=plaintext >0.005050182342529297</code></pre>
<pre><code class=language-julia >t₀ &#61; time&#40;&#41;
multAx2&#40;y, A, x&#41;
Δt &#61; time&#40;&#41; - t₀</code></pre><pre><code class=plaintext >0.001280069351196289</code></pre>
<pre><code class=language-julia >A &#61; rand&#40;3, 3&#41;
A&#91;:&#93;</code></pre><pre><code class=plaintext >9-element Vector{Float64}:
 0.12592383127519824
 0.4063946092151689
 0.8555454056193958
 0.9655295549364478
 0.07833452852304967
 0.4340232100672128
 0.7131603007139902
 0.03903373160157608
 0.30698615755540515</code></pre>
<p>Para matrizes esparsas, o armazenamento pode ser muito mais complicado. A estratégia mais simples é armazenar todos os índices e valores. No Julia, existem ferramentas para trabalhar com matrizes esparsas nativamente.</p>
<pre><code class=language-julia >using SparseArrays

A &#61; sprand&#40;4, 4, 0.3&#41;</code></pre><pre><code class=plaintext >4×4 SparseArrays.SparseMatrixCSC{Float64, Int64} with 7 stored entries:
  ⋅         ⋅         ⋅         ⋅ 
 0.152652   ⋅        0.143727   ⋅ 
 0.113762  0.358659   ⋅         ⋅ 
 0.299503  0.612308  0.636136   ⋅ </code></pre>
<pre><code class=language-julia >Matrix&#40;A&#41;</code></pre><pre><code class=plaintext >4×4 Matrix{Float64}:
 0.0       0.0       0.0       0.0
 0.152652  0.0       0.143727  0.0
 0.113762  0.358659  0.0       0.0
 0.299503  0.612308  0.636136  0.0</code></pre>
<pre><code class=language-julia >rows, cols, vals &#61; findnz&#40;A&#41;</code></pre><pre><code class=plaintext >([2, 3, 4, 3, 4, 2, 4], [1, 1, 1, 2, 2, 3, 3], [0.15265152417732009, 0.11376165502982749, 0.29950336069511074, 0.3586586928420774, 0.6123077282392284, 0.14372698286566488, 0.6361362986166581])</code></pre>
<pre><code class=language-julia >&#91;rows cols vals&#93;</code></pre><pre><code class=plaintext >7×3 Matrix{Float64}:
 2.0  1.0  0.152652
 3.0  1.0  0.113762
 4.0  1.0  0.299503
 3.0  2.0  0.358659
 4.0  2.0  0.612308
 2.0  3.0  0.143727
 4.0  3.0  0.636136</code></pre>
<pre><code class=language-julia >function multAxs&#40;y, rows, cols, vals, x&#41;
    n &#61; length&#40;y&#41;
    for i &#61; 1:n
        y&#91;i&#93; &#61; 0.0
    end
    nz &#61; length&#40;vals&#41;
    for k &#61; 1:nz
        i, j &#61; rows&#91;k&#93;, cols&#91;k&#93;
        y&#91;i&#93; &#43;&#61; vals&#91;k&#93; * x&#91;j&#93;
    end
end

x &#61; rand&#40;4&#41;
y &#61; A * x
ys &#61; zeros&#40;4&#41;
multAxs&#40;ys, rows, cols, vals, x&#41;</code></pre>
<pre><code class=language-julia >y - ys</code></pre><pre><code class=plaintext >4-element Vector{Float64}:
 0.0
 0.0
 0.0
 0.0</code></pre>
<pre><code class=language-julia >A</code></pre><pre><code class=plaintext >4×4 SparseArrays.SparseMatrixCSC{Float64, Int64} with 7 stored entries:
  ⋅         ⋅         ⋅         ⋅ 
 0.152652   ⋅        0.143727   ⋅ 
 0.113762  0.358659   ⋅         ⋅ 
 0.299503  0.612308  0.636136   ⋅ </code></pre>
<pre><code class=language-julia >A &#61; sprand&#40;1000, 1000, 0.001&#41;
A &#61; A * A&#39;</code></pre><pre><code class=plaintext >1000×1000 SparseArrays.SparseMatrixCSC{Float64, Int64} with 1540 stored entries:
⠑⢄⠀⠐⠂⠀⠄⠀⠐⠀⠄⠠⡠⡤⠄⡀⠘⡂⡀⢐⠀⠀⠤⡤⠂⠂⠀⢀⡠⠂⠐⠂⠂⠀⢂⢄⢀⣀⠠⣄
⢀⠀⡑⢌⢐⢀⠐⡂⢁⠁⡀⡀⠀⡂⠠⠐⢢⢈⡀⢅⠀⠀⠁⠈⡈⡀⠀⠀⠈⠄⠀⠈⡚⠀⠂⠠⠀⠐⠂⠀
⠈⠀⠐⢐⠑⢄⠑⡠⠀⠑⠊⠢⠀⠐⠀⠒⠀⠠⠄⠠⠈⢂⠀⠀⠀⠂⠘⠀⠠⠁⠀⠃⠁⠀⡁⠀⠁⠐⠠⠈
⠀⠁⠰⠠⠑⡠⠑⣤⠂⠐⠀⠒⠀⠔⠀⠒⠀⢄⠑⠀⢴⠀⠐⠀⠉⠄⠉⣄⠋⠨⠠⡀⢀⠀⠀⢅⠀⠊⠘⠋
⠐⠀⠅⠐⢄⠀⢈⠀⠑⢄⠀⡁⢀⠕⠀⡀⠁⠐⠀⠠⠂⠀⠂⠈⠠⠀⠄⠀⡁⠀⠄⠀⠀⡈⠀⠀⠄⢄⠀⠁
⠀⡁⠀⠨⠪⡀⢠⠀⠄⠠⠑⢄⠇⡠⠀⠠⠠⡄⠀⠀⡀⡀⡀⢕⡂⠩⠄⠀⢀⠬⠀⠀⠄⠁⠀⠠⠂⠠⠢⡆
⠀⡮⠠⠠⢀⠀⢀⠄⢄⠔⠉⡡⠑⢄⢀⠄⠀⠉⠑⠶⠀⡄⡠⠀⢔⡠⠳⠀⠄⠀⠀⡀⡂⠁⠀⢐⢰⠀⠐⠈
⠀⠡⢀⠂⢠⠀⢠⠀⠀⠠⠀⡀⠀⠔⠛⢄⠈⠀⠀⠀⠀⡀⠠⠀⠐⠀⠁⠐⠀⡀⠀⠂⠁⠉⠀⠀⠠⠀⠀⠃
⠲⠠⡈⢒⠀⡀⠀⢄⢁⠀⠀⠦⡄⠀⠂⠀⢵⢗⠁⠂⠀⠀⠀⡠⡉⠀⠀⠁⠀⠂⢀⢀⡀⠀⠐⠐⠁⠀⠀⡠
⢀⢈⠄⢌⠀⡁⠑⠀⠀⡀⠀⠀⢱⡄⠀⠀⠡⠀⢑⢔⡔⠀⠀⠀⠐⣀⠐⠀⠨⠀⠀⡀⣀⠀⠠⢰⡈⠃⠀⠀
⠀⠀⠀⠀⠢⢀⠐⠓⠈⠀⠀⠨⠀⠤⠀⠠⠀⠀⠐⠉⠑⢄⠐⠀⠒⠙⠂⠆⠂⡀⠀⠀⠀⠀⡀⠀⠀⠐⠈⠀
⠀⡧⡁⠀⠀⠀⠐⠀⡈⠀⢄⢌⠀⠊⠀⠂⠀⡠⠀⠀⠐⠀⡑⣬⠐⢒⠈⢠⢊⠀⠀⠠⠀⣀⠀⠠⠀⠁⠀⠀
⠨⠀⠂⠨⠠⠀⠃⠄⠀⠂⡌⡈⠐⡱⠐⠀⠃⠈⠐⢠⣜⠀⢰⢀⢛⢔⠕⠀⠂⠠⠁⠄⠀⡉⠐⠄⠡⠀⢰⠁
⠀⢀⠀⠀⠒⠀⠃⢤⠀⠁⠀⠁⠙⠂⢁⠀⠄⠀⠐⠀⠨⠄⠂⣀⠑⠁⠑⢄⡐⠀⠠⡀⠀⠁⡄⠙⠍⠈⡀⠐
⠠⠊⠂⠄⠄⠂⡋⡀⠁⠈⡀⡔⠀⠁⠀⠠⠠⠀⠂⠂⠈⠠⠊⠐⠈⡀⠐⠈⡑⣬⠲⠠⠄⠀⠁⠨⢀⡠⠁⠍
⠰⠀⡀⠀⠤⠀⠀⠢⠀⠁⠀⠀⠀⠠⠠⠀⠀⢐⠀⠠⠀⠀⠀⡀⠁⠄⠀⠢⠘⡂⡑⢌⠂⠈⠀⠠⠁⠠⠀⡀
⠈⠀⠚⠈⠁⠀⠀⠐⡀⠠⠄⠁⠌⠈⡅⠀⠀⠈⠀⠘⠀⠀⠀⢠⡄⠠⠄⠀⠀⠁⡈⠀⠑⢄⡀⠈⡠⠀⠂⠁
⠈⢔⠈⡀⠁⠈⠄⢄⠀⠀⠀⡀⢀⢀⠀⠀⢐⠀⢀⣂⠀⠈⠀⡀⠐⠄⣄⠉⡁⡀⠀⡀⡀⠈⠑⢄⠁⢀⠱⠀
⠀⢰⢀⠀⢁⠀⡠⠀⠀⢅⠈⡀⠐⠒⠀⠂⠁⠀⠦⠈⢀⠀⠄⠀⠁⠂⡃⠁⠀⡰⠁⡀⠀⠊⠁⢀⠑⢄⠢⠀
⠀⢦⠈⠀⡀⠂⡶⠀⠄⠀⠨⠦⡐⠀⠤⠀⠀⡠⠀⠀⠂⠀⠀⠀⠔⠒⢀⠈⡅⠄⠀⠠⠌⠀⠑⠂⠈⠂⡑⢌</code></pre>
<h1 id=sistemas_lineares ><a href="#sistemas_lineares" class=header-anchor >Sistemas Lineares</a></h1>
<p>Sistemas lineares são extremamentes importantes. Em quase todas aplicações avançadas teremos sistemas lineares. Em muitos casos, esses sistemas serão especiais, de modo que teremos métodos especiais para resolvê-los. Estudaremos aqui, no entanto, a maneira mais geral de resolvê-los. Estudos mais avançados serão feitos em disciplinas posteriores.</p>
<h2 id=a_barra_invertida ><a href="#a_barra_invertida" class=header-anchor >A barra invertida</a></h2>
<p>Em Julia e Matlab/Octave, existe um comando especial e simples para se resolver sistemas lineares: a barra invertida ....</p>
<pre><code class=language-julia >A &#61; rand&#40;3, 3&#41;
b &#61; A * ones&#40;3&#41;</code></pre><pre><code class=plaintext >3-element Vector{Float64}:
 1.9681159477327848
 1.3370926625978168
 1.032617290529063</code></pre>
<p>b foi criado para que Ax &#61; b tenha como solução o vetor de uns.</p>
<pre><code class=language-julia >x &#61; A\b</code></pre><pre><code class=plaintext >3-element Vector{Float64}:
 1.0
 1.0
 1.0</code></pre>
<pre><code class=language-julia >A &#61; zeros&#40;5,5&#41; &#43; 2I
for i &#61; 1:4
    A&#91;i,i&#43;1&#93; &#61; 1
    A&#91;i&#43;1,i&#93; &#61; 1
end
A</code></pre><pre><code class=plaintext >5×5 Matrix{Float64}:
 2.0  1.0  0.0  0.0  0.0
 1.0  2.0  1.0  0.0  0.0
 0.0  1.0  2.0  1.0  0.0
 0.0  0.0  1.0  2.0  1.0
 0.0  0.0  0.0  1.0  2.0</code></pre>
<pre><code class=language-julia >b &#61; A * ones&#40;5&#41;
A \ b</code></pre><pre><code class=plaintext >5-element Vector{Float64}:
 1.0
 1.0
 1.0
 1.0
 1.0</code></pre>
<p>A barra invertida facilita grandemente a resolução de sistemas. No entanto, é importante, principalmente para matemáticos industriais, aplicados e computacionais, entender o que acontece na resolução de um sistema. Além disso, também existem vários casos em que o uso da barra invertida será pior que o conhecimento específico sobre o problema.</p>
<h2 id="eliminação_gaussiana"><a href="#eliminação_gaussiana" class=header-anchor >Eliminação Gaussiana</a></h2>
<p>O método mais simples de resolução de sistemas lineares é o equivalente ao chamado escalonamento.</p>
<p>Relembrando. Dado uma matriz \(A\) e um vetor \(b\), o escalonamento da matriz aumentada \(\left[\begin{array}{cc} A & b \end{array}\right]\) é o processo de transformar essa matriz em uma matriz com vários zeros montando um tipo de escada. Com mais detalhes, é uma matriz tal que</p>
<ul>
<li><p>Todas as linhas começam com um ou mais zeros que a linha de cima, a não que seja toda nula;</p>

<li><p>Todas as linhas nulas estão abaixo de qualquer linha não toda nula.</p>

</ul>
<p>Uma matriz é transformada numa matriz escalonada através de operações elementares nas linhas da matriz. Essa operações são</p>
<ul>
<li><p>multiplicar uma linha por um número não-nulo;</p>

<li><p>trocar duas linhas de posição;</p>

<li><p>somar à uma linha um múltiplo de outra.</p>

</ul>
<p>Se \(A\) é uma matriz quadrada e inversível, então é garantido que a matriz aumentada escalonada será da forma \(\begin{bmatrix} U & c \end{bmatrix}\), onde \(U\) é uma matriz triangular superior com diagonal não nula, isto é \(b_{i,j} = 0\) se \(i > j\), e \(b_{i,i} \neq 0\). Em outras palavras, a primeira linha é não nula, e cada linha abaixo tem um zero a mais que a anterior.</p>
<p>Exemplo</p>
<pre><code class=language-julia >U &#61; triu&#40;rand&#40;1:999, 10, 10&#41;&#41; / 1000</code></pre><pre><code class=plaintext >10×10 Matrix{Float64}:
 0.632  0.812  0.015  0.341  0.276  0.311  0.236  0.955  0.318  0.751
 0.0    0.056  0.727  0.004  0.224  0.721  0.511  0.92   0.145  0.05
 0.0    0.0    0.03   0.832  0.111  0.729  0.172  0.397  0.371  0.11
 0.0    0.0    0.0    0.651  0.131  0.551  0.651  0.526  0.684  0.256
 0.0    0.0    0.0    0.0    0.45   0.254  0.019  0.497  0.244  0.582
 0.0    0.0    0.0    0.0    0.0    0.59   0.693  0.046  0.75   0.544
 0.0    0.0    0.0    0.0    0.0    0.0    0.139  0.143  0.197  0.106
 0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.792  0.346  0.045
 0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.976  0.96
 0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.859</code></pre>
<p>Computacionalmente, vamos fazer as mesmas operações, com exceção da multiplicação de uma linha por um número, por motivos que ficarão claros no futuro. Além disso, o motivo para se mudar as linhas ao fazer essas operações na mão era para facilitar as contas. Computacionalmente, teremos outros objetivos, e só faremos a mudança de linhas quando necessário.</p>
<p>Portanto, nossa operação principal será a adição de um múltiplo de outra linha a linha atual. Nossa notação será</p>
\[ L_j \leftarrow L_j + \alpha L_i, \]
<p>para dizer que multiplicamos a linha \(i\) por \(\alpha\), somamos à linha \(j\) e substituímos na linha \(j\).</p>
<p>Vamos exemplificar o processo que já conhecemos.</p>
<pre><code class=language-julia >A &#61; &#91;3.0 1 2; -1 2 1; 1 1 4&#93;

b &#61; &#91;6.0; 2; 6&#93;

m21 &#61; A&#91;2,1&#93; / A&#91;1,1&#93;</code></pre><pre><code class=plaintext >-0.3333333333333333</code></pre>
<p>Li &#61; B&#91;i,:&#93; L₂ ← L₂ - m₂₁L₁</p>
<pre><code class=language-julia >A&#91;2,:&#93; &#61; A&#91;2,:&#93; - m21 * A&#91;1,:&#93;
b&#91;2&#93; &#61; b&#91;2&#93; - m21 * b&#91;1&#93;</code></pre><pre><code class=plaintext >4.0</code></pre>
<p>Note que A&#91;2,1&#93; é zero agora</p>
<pre><code class=language-julia >&#91;A b&#93;</code></pre><pre><code class=plaintext >3×4 Matrix{Float64}:
 3.0  1.0      2.0      6.0
 0.0  2.33333  1.66667  4.0
 1.0  1.0      4.0      6.0</code></pre>
<p>L₃ ← L₃ - m₃₁L₁</p>
<pre><code class=language-julia >m31 &#61; A&#91;3,1&#93;/A&#91;1,1&#93;
A&#91;3,:&#93; &#61; A&#91;3,:&#93; - m31*A&#91;1,:&#93;
b&#91;3&#93; &#61; b&#91;3&#93; - m31*b&#91;1&#93;

&#91;A b&#93;</code></pre><pre><code class=plaintext >3×4 Matrix{Float64}:
 3.0  1.0       2.0      6.0
 0.0  2.33333   1.66667  4.0
 0.0  0.666667  3.33333  4.0</code></pre>
<p>L₃ ← L₃ - m₃₂L₂</p>
<pre><code class=language-julia >m32 &#61; A&#91;3,2&#93;/A&#91;2,2&#93;
A&#91;3,:&#93; &#61; A&#91;3,:&#93; - m32*A&#91;2,:&#93;
b&#91;3&#93; &#61; b&#91;3&#93; - m32*b&#91;2&#93;

&#91;A b&#93;</code></pre><pre><code class=plaintext >3×4 Matrix{Float64}:
 3.0   1.0          2.0      6.0
 0.0   2.33333      1.66667  4.0
 0.0  -1.11022e-16  2.85714  2.85714</code></pre>
<p>Agora podemos resolver esse sistema triangular superior facilmente. Note que, tirando o erro numérico em <code>A&#91;3,2&#93;</code>, temos</p>
\[\begin{aligned}
a_{11} x_1 + a_{12} x_2 + a_{13} & = b_1 \\
a_{22} x_2 + a_{23} x_3 & = b_2 \\
a_{33} x_3 & = b_3.
\end{aligned}\]
<p>Assim, resolvemos esse sistema fazendo</p>
\[\begin{aligned}
x_3 & = \frac{b_3}{a_{33}} \\
x_2 & = \frac{b_2 - a_{23}x_3}{a_{22}} \\
x_1 & = \frac{b_1 - a_{13}x_3 - a_{12}x_2}{a_{11}}.
\end{aligned}\]
<pre><code class=language-julia >x &#61; zeros&#40;3&#41;
x&#91;3&#93; &#61; b&#91;3&#93; / A&#91;3,3&#93;
x&#91;2&#93; &#61; &#40;b&#91;2&#93; - A&#91;2,3&#93; * x&#91;3&#93;&#41; / A&#91;2,2&#93;
x&#91;1&#93; &#61; &#40;b&#91;1&#93; - A&#91;1,3&#93; * x&#91;3&#93; - A&#91;1,2&#93; * x&#91;2&#93;&#41; / A&#91;1,1&#93;
x</code></pre><pre><code class=plaintext >3-element Vector{Float64}:
 1.0
 1.0000000000000002
 0.9999999999999999</code></pre>
<p>O processo todo pode ser separado em duas partes:</p>
<ul>
<li><p>A redução à matriz triangular superior, que chamamos de <strong>Eliminação Gaussiana</strong>; e</p>

<li><p>A resolução do sistema triangular superior.</p>

</ul>
<p>O seguinte algoritmo descreve o processo</p>
<ol>
<li><p>Entrada:</p>
<ul>
<li><p>matriz \(A\) \(n \times n\)</p>

<li><p>vetor \(b\) de tamanho \(n\)</p>

</ul>

<li><p>Para \(j\) de \(1\) a \(n-1\)</p>
<ol>
<li><p>Para \(i\) de \(j+1\) a \(n\)</p>
<ol>
<li><p>Calcule \(m_{ij} = \dfrac{a_{ij}}{a_{jj}}\)</p>

<li><p>Faça \(L_i ← L_i - m_{ij}L_j\)</p>

<li><p>Faça \(b_i ← b_i - m_{ij}b_j\)</p>

</ol>

</ol>

<li><p>Saída:</p>
<ul>
<li><p>\(A\) triangular superior</p>

<li><p>\(b\) com modificações correspondentes.</p>

</ul>

</ol>
<p>Note que para ser bem definido, esse algoritmo precisa que \(a_{jj} \neq 0\). Existe um teorema indicando as condições para isso. Antes, definimos \(A_{kk}\) como a submatriz de \(A\) das linhas 1 a \(k\) e colunas 1 a \(k\). Em Julia seria a matriz <code>A&#91;1:k,1:k&#93;</code>.</p>
<p><strong>Teorema:</strong> Se \(\det(A_{kk}) \neq 0\) para todo \(k = 1,\dots,n-1\), então o método de Eliminação Gaussiana como descrito acima está bem definida, isto é, roda todas as iterações até encontrar uma matriz triangular superior. Se, além disso, \(\det(A) \neq 0\), então a diagonal é não-nula. Caso contrário, o último elemento da diagonal será \(0\).</p>
<p>Como isso nem sempre será possível, vamos colocar essa condição para falha no algoritmo. Se o elemento da diagonal for muito próximo de zero, retornaremos um erro.</p>
<pre><code class=language-julia >function elim_gauss&#40;A, b; diagtol &#61; 1e-12&#41;
    n &#61; size&#40;A, 1&#41;
    for j &#61; 1:n-1
        if abs&#40;A&#91;j,j&#93;&#41; &lt; diagtol
            error&#40;&quot;Diagonal quase nula&quot;&#41;
        end
        for i &#61; j&#43;1:n
            mij &#61; A&#91;i,j&#93; / A&#91;j,j&#93;
            A&#91;i,1:j&#93; .&#61; 0.0
            A&#91;i,j&#43;1:n&#93; -&#61; mij * A&#91;j,j&#43;1:n&#93;
            b&#91;i&#93; -&#61; mij * b&#91;j&#93;
        end
    end
    return A, b
end

A &#61; &#91;3.0 1 2; -1 2 1; 1 1 4&#93;
b &#61; &#91;6.0; 2; 6&#93;
elim_gauss&#40;A, b&#41;</code></pre><pre><code class=plaintext >([3.0 1.0 2.0; 0.0 2.3333333333333335 1.6666666666666665; 0.0 0.0 2.857142857142857], [6.0, 4.0, 2.8571428571428568])</code></pre>
<pre><code class=language-julia >&#91;A b&#93;</code></pre><pre><code class=plaintext >3×4 Matrix{Float64}:
 3.0  1.0      2.0      6.0
 0.0  2.33333  1.66667  4.0
 0.0  0.0      2.85714  2.85714</code></pre>
<pre><code class=language-julia >A \ b</code></pre><pre><code class=plaintext >3-element Vector{Float64}:
 1.0
 1.0000000000000002
 0.9999999999999999</code></pre>
<pre><code class=language-julia >A &#61; &#91;0.0 1.0; 1.0 0.0&#93;</code></pre><pre><code class=plaintext >2×2 Matrix{Float64}:
 0.0  1.0
 1.0  0.0</code></pre>
<pre><code class=language-julia >b &#61; ones&#40;2&#41;
elim_gauss&#40;A, b&#41;</code></pre><pre><code class=plaintext >Diagonal quase nula
</code></pre>
<pre><code class=language-julia >A &#61; &#91;3.0 1 2; -1 2 1; 1 1 4&#93;
b &#61; &#91;6.0; 2; 6&#93;
A \ b</code></pre><pre><code class=plaintext >3-element Vector{Float64}:
 1.0
 1.0000000000000002
 0.9999999999999999</code></pre>
<p>Agora para o algoritmo de resolução do sistema triangular superior.</p>
<ol>
<li><p>Entrada:</p>
<ul>
<li><p>\(A\): \(n \times n\) triangular superior com diagonal não-nula</p>

<li><p>\(b\): \(n\)</p>

</ul>

<li><p>Crie o vetor \(x\) nulo</p>

<li><p>Para \(i\) de \(n\) à \(1\)</p>
<ol>
<li><p>\(s \leftarrow b_i\)</p>

<li><p>Para \(j\) de \(i+1\) à \(n\)</p>
<ol>
<li><p>\(s \leftarrow s - a_{ij}x_j\)</p>

</ol>

<li><p>\(x_i = \dfrac{s}{a_{ii}}\)</p>

</ol>

<li><p>Saída:</p>
<ul>
<li><p>\(x\) solução de \(Ax = b\)</p>

</ul>

</ol>
<pre><code class=language-julia >function sist_tri_sup&#40;A, b&#41;
    n &#61; length&#40;b&#41;
    x &#61; zeros&#40;n&#41;
    for j &#61; n:-1:1
        if abs&#40;A&#91;j,j&#93;&#41; &lt; 1e-14
            error&#40;&quot;Não deu&quot;&#41;
        end
        s &#61; b&#91;j&#93;
        for k &#61; j&#43;1:n
            s -&#61; A&#91;j,k&#93; * x&#91;k&#93;
        end
        x&#91;j&#93; &#61; s / A&#91;j,j&#93;
    end
    return x
end

A &#61; &#91;3.0 1 2; -1 2 1; 1 1 4&#93;
b &#61; &#91;6.0;2;6&#93;
elim_gauss&#40;A, b&#41;
sist_tri_sup&#40;A, b&#41;</code></pre><pre><code class=plaintext >3-element Vector{Float64}:
 1.0
 1.0000000000000002
 0.9999999999999999</code></pre>
<pre><code class=language-julia >function resolve&#40;A, b&#41;
    Ac &#61; copy&#40;A&#41;
    bc &#61; copy&#40;b&#41;
    elim_gauss&#40;Ac, bc&#41;
    x &#61; sist_tri_sup&#40;Ac, bc&#41;
    return x
end

A &#61; rand&#40;100, 100&#41;
b &#61; A * ones&#40;100&#41;;</code></pre>
<pre><code class=language-julia >&#40;100 * 100 &#43; 100 &#43; 100&#41; * Float64.size / 1024</code></pre><pre><code class=plaintext >79.6875</code></pre>
<pre><code class=language-julia >@time x &#61; resolve&#40;A, b&#41;;</code></pre><pre><code class=plaintext >  0.013401 seconds (21.27 k allocations: 12.167 MiB, 34.83% compilation time)
</code></pre>
<pre><code class=language-julia >@time x &#61; A \ b;</code></pre><pre><code class=plaintext >  0.000296 seconds (4 allocations: 79.953 KiB)
</code></pre>
<h2 id=pontos_importantes ><a href="#pontos_importantes" class=header-anchor >Pontos importantes</a></h2>
<ul>
<li><p>\(A\) foi perdida. Ela é irrecuperável &#40;sem os valores de \(m_{i,j})\). Para prevenir isso, podemos</p>
<ul>
<li><p>Sol. 1: Não &quot;usar&quot; \(A\), i.e., copiar para outra matriz</p>

<li><p>Sol. 2: Guardar \(m_{i,j}\).</p>

</ul>

<li><p>A eliminação do elemento \(a_{i,j}\) faz contas desnecessárias com 0.0 &#40;antes da coluna \(j\)&#41;.</p>

<li><p>\(m_{i,j}\) foi calculado com o objetivo de transformar</p>

</ul>
<p>\(a_{i,j}\) em 0.0. Então não é necessário calcular a atualização de \(a_{i,j}\). &#40;Basta fazer <code>A&#91;i,j&#93; &#61; 0.0</code>&#41;. Sem falar que o resultado pode não ser exatamente 0.0, e ficar sujando as contas.</p>
<ul>
<li><p>A matriz resultante tem muitos zeros, i.e., gasto de memória a toa.</p>
<ul>
<li><p>Sol.: Guardar a matriz de um jeito diferente;</p>

<li><p>Sol.: Usar esse espaço vazio.</p>

</ul>

<li><p><code>A&#91;i,:&#93;</code> cria um vetor temporario, então</p>

</ul>
<p>\(L_i \leftarrow L_i - m_{i,j}L_j\) tem um gasto de memória desnecessário.     - Nesta disciplina, vamos ignorar esse fato, sempre que não afetar demais;     - A maneira tradicional de resolver esse problema é usar <code>for</code>;     - O Julia permite alguns comandos que fazem isso automático pra você.</p>
<p>Uma melhoria no método, que zera os elementos que deveriam ser zerados e restringe as contas feitas, está abaixo.</p>
<pre><code class=language-julia >function elim_gauss&#40;A, b; diagtol &#61; 1e-12&#41;
    n &#61; length&#40;b&#41;
    for j &#61; 1:n-1
        ajj, bj &#61; A&#91;j,j&#93;, b&#91;j&#93;
        if abs&#40;ajj&#41; &lt;&#61; diagtol
            error&#40;&quot;Diagonal muito próxima de 0&quot;&#41;
        end
        for i &#61; j&#43;1:n
            mij &#61; A&#91;i,j&#93; / ajj
            A&#91;i,j&#93; &#61; 0.0
            A&#91;i,j&#43;1:n&#93; -&#61; mij * A&#91;j,j&#43;1:n&#93;
            b&#91;i&#93; -&#61; mij * bj
        end
    end
    return A, b
end

A &#61; &#91;3.0 1 2; -1 2 1; 1 1 4&#93;
b &#61; &#91;6.0;2;6&#93;
elim_gauss&#40;A, b&#41;
A</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 3.0  1.0      2.0
 0.0  2.33333  1.66667
 0.0  0.0      2.85714</code></pre>
<pre><code class=language-julia >A \ b</code></pre><pre><code class=plaintext >3-element Vector{Float64}:
 1.0
 1.0000000000000002
 0.9999999999999999</code></pre>
<pre><code class=language-julia >A &#61; &#91;1 1e-11; 1e-11 100&#93;
b &#61; A * ones&#40;2&#41;
resolve&#40;A, b&#41; .- 1</code></pre><pre><code class=plaintext >2-element Vector{Float64}:
 0.0
 0.0</code></pre>
<pre><code class=language-julia >A &#61; &#91;1e-11 100; 1 1e-11&#93;
b &#61; A * ones&#40;2&#41;
resolve&#40;A, b&#41; .- 1</code></pre><pre><code class=plaintext >2-element Vector{Float64}:
 0.0004441719502210617
 0.0</code></pre>
<pre><code class=language-julia >cond&#40;A&#41;</code></pre><pre><code class=plaintext >100.0</code></pre>
<h2 id=pivoteamento ><a href="#pivoteamento" class=header-anchor >Pivoteamento</a></h2>
<p>Pivoteamento é o nome dado à troca de linhas no processo de eliminação Gaussiana. Às vezes podemos fazer troca de colunas também, e para diferenciar costuma-se dizer eliminação Gaussiana com pivoteamento parcial.</p>
<p>O primeiro motivo pelo qual o pivoteamento é importante é o zero na diagonal.</p>
<pre><code class=language-julia >A &#61; &#91;0 1; 1 0&#93;</code></pre><pre><code class=plaintext >2×2 Matrix{Int64}:
 0  1
 1  0</code></pre>
<p>Essa matriz, apesar de trivial, não passa no teste da nossa função de eliminação Gaussiana. Além disso, existem outros problemas.</p>
<pre><code class=language-julia >ϵ &#61; 1e-12
A &#61; &#91;ϵ 100; 1.0 ϵ&#93;
B &#61; copy&#40;A&#41;
b &#61; A * ones&#40;2&#41;
elim_gauss&#40;A, b, diagtol&#61;0.0&#41;</code></pre><pre><code class=plaintext >([1.0e-12 100.0; 0.0 -1.0e14], [100.000000000001, -1.0e14])</code></pre>
<pre><code class=language-julia >x &#61; sist_tri_sup&#40;A, b&#41;
x - ones&#40;2&#41;</code></pre><pre><code class=plaintext >2-element Vector{Float64}:
 -0.00524016993585974
  0.0</code></pre>
<pre><code class=language-julia >ϵ &#61; 1e-15
&#40;&#40;100 &#43; ϵ&#41; - 100&#41; / ϵ</code></pre><pre><code class=plaintext >0.0</code></pre>
<pre><code class=language-julia >A &#61; B&#91;&#91;2;1&#93;, :&#93;</code></pre><pre><code class=plaintext >2×2 Matrix{Float64}:
 1.0        1.0e-12
 1.0e-12  100.0</code></pre>
<pre><code class=language-julia >b &#61; A * ones&#40;2&#41;
elim_gauss&#40;A, b&#41;
x &#61; sist_tri_sup&#40;A, b&#41;
x - ones&#40;2&#41;</code></pre><pre><code class=plaintext >2-element Vector{Float64}:
 0.0
 0.0</code></pre>
<pre><code class=language-julia >using LinearAlgebra
cond&#40;A&#41;</code></pre><pre><code class=plaintext >100.0</code></pre>
<p>A matriz \(A\) no exemplo acima</p>
\[ A = \left[\begin{array}{cc}
\epsilon & 100 \\
1 & \epsilon
\end{array}\right],\]
<p>introduz um problema durante a eliminação Gaussiana. O elemento \(a_{22}\) deve ser substituído por</p>
\[ \epsilon - \frac{100}{\epsilon}. \]
<p>Quando \(\epsilon\) é pequeno, ocorre um underflow considerável nessa operação, de modo que fica aproximada por \(-\dfrac{100}{\epsilon}\).</p>
<p>O vetor \(b\), que inicialmente é \(\left[\begin{array}{c} 100 + \epsilon \\ 1 + \epsilon\end{array}\right],\) vira \(\left[\begin{array}{c} 100 + \epsilon \\ 1 + \epsilon - \dfrac{100 + \epsilon}{\epsilon} \end{array}\right],\)</p>
<p>Nem \(100 + \epsilon\), nem \(1 + \epsilon\) têm erros grandes. Por outro lado,</p>
\[ 1 + \epsilon - \frac{100 + \epsilon}{\epsilon} = \epsilon - \frac{100}{\epsilon} \approx -\frac{100}{\epsilon}.\]
<p>Ou seja, acaba acontecendo um erro similar em \(b_2\), de modo que o \(x_2\) encontrado é \(1.0\).</p>
<p>Daí,</p>
\[ x_1 = \frac{ (100 + \epsilon) - 100 }{\epsilon}. \]
<p>A subtração tem um erro pequeno, mas quando dividido por \(\epsilon\), fica considerável.</p>
<p>A matriz com as linhas trocadas, no entanto, não teve esse problema.</p>
\[ A = \begin{bmatrix}
1 & \epsilon \\
\epsilon & 100
\end{bmatrix}
\qquad
\text{e}
\qquad
b = \left[\begin{array}{c}
1 + \epsilon \\
100 + \epsilon
\end{array}\right]
.\]
<p>Temos </p>
\[ m_{21} = \epsilon, \]
<p>daí</p>
\[ a_{22} \leftarrow 100 - \epsilon^2 \approx 100, \]
<p>e</p>
\[ b_2 \leftarrow (100 + \epsilon) - \epsilon (1 + \epsilon) \approx 100. \]
<p>Novamente \(x_2 = 1\). Agora</p>
\[ x_1 = \frac{ (1 + \epsilon) - \epsilon }{1} = 1. \]
<p>Novamente o erro na subtração é grande, porém a divisão não aumenta esse erro.</p>
<p>Em outras palavras, podemos tentar pivotear a matriz \(A\) para <strong>aumentar a estabilidade numérica</strong>. Outro motivo para o pivoteamento está abaixo.</p>
<h3 id=esparsidade ><a href="#esparsidade" class=header-anchor >Esparsidade</a></h3>
<p>Uma matriz é dita <strong>esparsa</strong> se contém muitos zeros. Esse termo não é exato, o que complica um pouco, e não faz muito sentido para matrizes pequenas, mas vamos tentar elucidá-lo e explicar a sua importância.</p>
<p>A densidade de \(A\) é o número de elementos não nulos divido pelo número de elementos total de \(A\).</p>
<p>Em geral, o limite para se considerar uma matriz esparsa não é estabelecido, principalmente por depender da dimensão \(n\) de \(A\). Em geral, uma matriz com 1&#37; de elementos não nulos é considerada esparsa. Uma com 10&#37; às vezes será considerada esparsa. Uma matriz diagonal, por exemplo, é a matriz mais esparsa possível que pode ser não-singular &#40;permutações da matriz diagonal também&#41;. O número de elementos não-nulos da matriz diagonal é \(n\), e seu número de elementos é \(n^2\). Portanto, sua densidade é \(1/n\). Se \(n > 1000\), então a densidade será menor que \(0.001\).</p>
<p>Uma matriz tridiagonal - onde só podem ser não-nulos os elementos na diagonal, na diagonal acima, e na diagonal abaixo, terá densidade \(\dfrac{3n-2}{n^2}\). No caso \(n = 1000\), será \(\approx 0.003\), e ainda é considerada esparsa.</p>
<p>Uma matriz de banda \(k\) - onde as diagonais até \(k\) acima e até \(k\) abaixo da diagonal principal contém todos os elementos não-nulos - tem \(n + 2(n-1) + 2(n-2) + \dots 2(n-k) = n + 2\sum_{i = 1}^k(n-i) = n(1 + 2k) - k(k+1)\) elementos. Uma matriz com \(n = 1000\) e \(k = 50\), terá esparsidade \(\approx 0.1\), que ainda está bom. Veja que já é 10&#37;.</p>
<p>Quando fazemos operações com matrizes esparsas, os cálculos envolvendo os elementos nulos tem custo nulo, além de não produzirem erros. Além disso, uma matriz esparsa irá ocupar muito menos espaço no computador. Por isso matrizes esparsas são desejáveis. Por outro lado, algumas operações na matriz fazem com que sua densidade aumente, por isso devemos tomar muito cuidade em como fazê-las.</p>
<p>Em particular, uma matriz esparsa pode se tornar bastante densa na operação de eliminação Gaussiana.</p>
<pre><code class=language-julia >using SparseArrays</code></pre>
<pre><code class=language-julia >n &#61; 100
A &#61; spdiagm&#40;0 &#61;&gt; ones&#40;n&#41;&#41;
A&#91;:,1&#93; .&#61; 1.0
A&#91;1,:&#93; .&#61; 1.0
A&#91;1,1&#93; &#61; n
A</code></pre><pre><code class=plaintext >100×100 SparseArrays.SparseMatrixCSC{Float64, Int64} with 298 stored entries:
⡟⢍⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉
⡇⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄</code></pre>
<pre><code class=language-julia >b &#61; A * ones&#40;n&#41;
elim_gauss&#40;A, b&#41;
A</code></pre><pre><code class=plaintext >100×100 SparseArrays.SparseMatrixCSC{Float64, Int64} with 10000 stored entries:
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿</code></pre>
<p>A matriz \(A\) acima é o mais densa possível &#40;para uma matriz triangular superior&#41;. No entanto, uma simples mudança de linhas resolveria o problema.</p>
<pre><code class=language-julia >n &#61; 100
A &#61; spdiagm&#40;0 &#61;&gt; ones&#40;n&#41;&#41;
A&#91;:,1&#93; .&#61; 1
A&#91;1,:&#93; .&#61; 1
A&#91;1,1&#93; &#61; n
A&#91;&#91;1;n&#93;,:&#93; &#61; A&#91;&#91;n;1&#93;,:&#93;
A</code></pre><pre><code class=plaintext >100×100 SparseArrays.SparseMatrixCSC{Float64, Int64} with 396 stored entries:
⡟⢍⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉
⡇⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀
⣇⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣑⣄</code></pre>
<pre><code class=language-julia >elim_gauss&#40;A, b&#41;
A</code></pre><pre><code class=plaintext >100×100 SparseArrays.SparseMatrixCSC{Float64, Int64} with 494 stored entries:
⡟⢍⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⢹
⡇⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸
⡇⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸
⡇⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸
⡇⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⢸
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⠀⠀⢸
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⠀⠀⢸
⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢄⠀⢸
⣇⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣑⣼</code></pre>
<p>Esse tipo de pivoteamento melhora a esparsidade, e costuma ser chamado de <strong>pivoteamento para reduzir o preenchimento</strong>.</p>
<h3 id=como_fazer_o_pivoteamento ><a href="#como_fazer_o_pivoteamento" class=header-anchor >Como fazer o pivoteamento</a></h3>
<p>Infelizmente, o pivoteamento para reduzir o preenchimento é complicado. Ele envolve procedimentos mais avançados e com menos garantias de que vai funcionar. Por outro lado, o pivoteamento para melhorar a estabilidade numérica tem procedimentos mais básicos com verificações imediatas. Desse modo, iremos focar nesse tipo de pivoteamento.</p>
<p>O pivoteamento para melhor a estabilidade numérica é feita escolhendo a linha a partir do <strong>maior elemento em módulo da coluna atual</strong> do método. Esse elemento, divo <strong>pivô</strong> é escolhido para ficar na diagonal da matriz, de modo que todos os \(m_{ij}\) calculados satisfazem \(|m_{ij}| \leq 1\). O processo está descrito abaixo.</p>
<pre><code class=language-julia >using Random
Random.seed&#33;&#40;0&#41;
A &#61; rand&#40;4, 4&#41; - rand&#40;4, 4&#41;
b &#61; A * ones&#40;4&#41;
C &#61; &#91;A b&#93;</code></pre><pre><code class=plaintext >4×5 Matrix{Float64}:
  0.24776    -0.190424  0.318687  -0.345261   0.030763
  0.0420778   0.141109  0.705232   0.774302   1.66272
 -0.803234   -0.310827  0.518965  -0.671082  -1.26618
 -0.590361   -0.699333  0.382653  -0.259264  -1.16631</code></pre>
<p>Coluna 1</p>
<pre><code class=language-julia >i &#61; argmax&#40;abs.&#40;C&#91;:,1&#93;&#41;&#41;
C&#91; &#91;i; 1&#93;, :&#93; &#61; C&#91; &#91;1; i&#93;, :&#93; # Lᵢ ↔ L₁
C</code></pre><pre><code class=plaintext >4×5 Matrix{Float64}:
 -0.803234   -0.310827  0.518965  -0.671082  -1.26618
  0.0420778   0.141109  0.705232   0.774302   1.66272
  0.24776    -0.190424  0.318687  -0.345261   0.030763
 -0.590361   -0.699333  0.382653  -0.259264  -1.16631</code></pre>
<pre><code class=language-julia >m &#61; C&#91;2:4, 1&#93; / C&#91;1,1&#93;         #Não se assustem
C&#91;2:4,2:5&#93; .-&#61; m * C&#91;1,2:5&#93;&#39;   # O código está com truques para ser curto
C&#91;2:4,1&#93; .&#61; 0.0                #Mas o resultado é o mesmo que fazer individualmente
C                              #Lᵢ ← Lᵢ - mᵢ₁L₁, i &#61; 2,3,4</code></pre><pre><code class=plaintext >4×5 Matrix{Float64}:
 -0.803234  -0.310827  0.518965    -0.671082  -1.26618
  0.0        0.124826  0.732418     0.739147   1.59639
  0.0       -0.286299  0.478764    -0.552258  -0.359794
  0.0       -0.470881  0.00122319   0.233969  -0.235689</code></pre>
<pre><code class=language-julia >i &#61; argmax&#40;abs.&#40;C&#91;2:4,2&#93;&#41;&#41; &#43; 1
C&#91; &#91;i; 2&#93;, :&#93; &#61; C&#91; &#91;2; i&#93;, :&#93;
C</code></pre><pre><code class=plaintext >4×5 Matrix{Float64}:
 -0.803234  -0.310827  0.518965    -0.671082  -1.26618
  0.0       -0.470881  0.00122319   0.233969  -0.235689
  0.0       -0.286299  0.478764    -0.552258  -0.359794
  0.0        0.124826  0.732418     0.739147   1.59639</code></pre>
<pre><code class=language-julia >m &#61; C&#91;3:4, 2&#93; / C&#91;2,2&#93;
C&#91;3:4,3:5&#93; .-&#61; m * C&#91;2,3:5&#93;&#39;
C&#91;3:4,2&#93; .&#61; 0.0
C                              #Lᵢ ← Lᵢ - mᵢ₂L₂, i &#61; 3,4</code></pre><pre><code class=plaintext >4×5 Matrix{Float64}:
 -0.803234  -0.310827  0.518965    -0.671082  -1.26618
  0.0       -0.470881  0.00122319   0.233969  -0.235689
  0.0        0.0       0.47802     -0.694513  -0.216493
  0.0        0.0       0.732742     0.80117    1.53391</code></pre>
<pre><code class=language-julia >i &#61; argmax&#40;abs.&#40;C&#91;3:4,3&#93;&#41;&#41; &#43; 2
C&#91; &#91;i; 3&#93;, :&#93; &#61; C&#91; &#91;3; i&#93;, :&#93;
C</code></pre><pre><code class=plaintext >4×5 Matrix{Float64}:
 -0.803234  -0.310827  0.518965    -0.671082  -1.26618
  0.0       -0.470881  0.00122319   0.233969  -0.235689
  0.0        0.0       0.732742     0.80117    1.53391
  0.0        0.0       0.47802     -0.694513  -0.216493</code></pre>
<pre><code class=language-julia >m &#61; C&#91;4,3&#93; / C&#91;3,3&#93;
C&#91;4,4:5&#93; .-&#61; m * C&#91;3,4:5&#93;
C&#91;4,3&#93; &#61; 0.0
C</code></pre><pre><code class=plaintext >4×5 Matrix{Float64}:
 -0.803234  -0.310827  0.518965    -0.671082  -1.26618
  0.0       -0.470881  0.00122319   0.233969  -0.235689
  0.0        0.0       0.732742     0.80117    1.53391
  0.0        0.0       0.0         -1.21717   -1.21717</code></pre>
<pre><code class=language-julia >U &#61; C&#91;1:4, 1:4&#93;
c &#61; C&#91;1:4, 5&#93;
U \ c</code></pre><pre><code class=plaintext >4-element Vector{Float64}:
 0.9999999999999998
 1.0000000000000002
 0.9999999999999997
 1.0</code></pre>
<ol>
<li><p>Entrada:</p>
<ul>
<li><p>matriz \(A\) \(n \times n\)</p>

<li><p>vetor \(b\) de tamanho \(n\)</p>

</ul>

<li><p>Para \(j\) de \(1\) a \(n-1\)</p>
<ol>
<li><p>Encontra a linha \(k = \argmax \{|a_{ij}| : i = j,\dots,n\}\) onde fica o pivô.</p>

<li><p>Faça \(L_k \leftrightarrow L_j\)</p>

<li><p>Faça \(b_k \leftarrow b_j\)</p>

<li><p>Para \(i\) de \(j+1\) a \(n\)</p>
<ol>
<li><p>Calcule \(m_{ij} = a_{ij}/a_{jj}\)</p>

<li><p>Faça \(L_i \leftarrow L_i - m_{ij}L_j\)</p>

<li><p>Faça \(b_i \leftarrow b_i - m_{ij}b_j\)</p>

</ol>

</ol>

<li><p>Saída:</p>
<ul>
<li><p>\(A\) triangular superior e</p>

<li><p>\(b\) com modificações correspondentes.</p>

</ul>

</ol>
<p>A troca de linhas, como já feito anteriormente, é dada por</p>
<pre><code class=language-julia >A &#61; rand&#40;5,5&#41;
j, k &#61; 2, 5
A&#91;&#91;k;j&#93;,:&#93; &#61; A&#91;&#91;j;k&#93;,:&#93;
A</code></pre><pre><code class=plaintext >5×5 Matrix{Float64}:
 0.300075  0.0353445  0.124323   0.838075  0.654922
 0.801924  0.801119   0.104823   0.873581  0.548342
 0.119653  0.899199   0.0795545  0.312145  0.632696
 0.76707   0.951691   0.776674   0.196407  0.735004
 0.72285   0.484661   0.114269   0.184115  0.586712</code></pre>
<pre><code class=language-julia >function elim_gauss_pivot&#40;A, b; diagtol &#61; 1e-12&#41;
    n &#61; length&#40;b&#41;
    for j &#61; 1:n-1
        pivo &#61; 0.0
        k &#61; j
        for i &#61; j:n
            if abs&#40;A&#91;i,j&#93;&#41; &gt; pivo
                pivo &#61; abs&#40;A&#91;i,j&#93;&#41;
                k &#61; i
            end
        end
        if k &#33;&#61; j
            A&#91; &#91;j, k&#93;, :&#93; &#61; A&#91; &#91;k, j&#93;, :&#93;
            b&#91; &#91;j, k&#93; &#93;   &#61; b&#91; &#91;k, j&#93; &#93;
        end
        ajj, bj &#61; A&#91;j,j&#93;, b&#91;j&#93;
        if abs&#40;ajj&#41; &lt;&#61; diagtol
            error&#40;&quot;Diagonal muito próxima de 0&quot;&#41;
        end
        for i &#61; j&#43;1:n
            mij &#61; A&#91;i,j&#93; / ajj
            A&#91;i,j&#93; &#61; 0.0
            A&#91;i,j&#43;1:n&#93; -&#61; mij * A&#91;j,j&#43;1:n&#93;
            b&#91;i&#93; -&#61; mij * bj
        end
    end
    return A, b
end

A &#61; rand&#40;4, 4&#41;
b &#61; A * ones&#40;4&#41;
elim_gauss_pivot&#40;A, b&#41;</code></pre><pre><code class=plaintext >([0.7913462490414747 0.8422557594578175 0.5058046332164718 0.5058741376644247; 0.0 0.11682520422031732 0.5907585334434668 0.3606584626063668; 0.0 0.0 0.7594577655944923 0.07851606035207387; 0.0 0.0 0.0 0.30820672286451894], [2.6452807793801885, 1.068242200270151, 0.8379738259465666, 0.3082067228645194])</code></pre>
<pre><code class=language-julia >A \ b</code></pre><pre><code class=plaintext >4-element Vector{Float64}:
 1.0000000000000044
 0.9999999999999949
 1.0000000000000002
 1.0000000000000013</code></pre>
<pre><code class=language-julia >A &#61; &#91;1e-12 100; 1 1e-12&#93;
b &#61; A * ones&#40;2&#41;
elim_gauss_pivot&#40;A, b&#41;</code></pre><pre><code class=plaintext >([1.0 1.0e-12; 0.0 100.0], [1.000000000001, 100.0])</code></pre>
<pre><code class=language-julia >A \ b</code></pre><pre><code class=plaintext >2-element Vector{Float64}:
 1.0
 1.0</code></pre>
<p>O processo de pivoteamento tem vantagens teóricas também. Note que o maior elemento do restante da coluna é escolhido. Isso quer dizer que se o pivô for nulo &#40;ou suficientemente próximo&#41;, então realmente não existe a possibilidade de escalonar aquela matriz com a diagonal diferente de zero. Em outras palavras, se \(A\) é inversível, então a eliminação Gaussiana com pivoteamento deveria funcionar &#40;na aritmética exata&#41;.</p>
<p><strong>Teorema:</strong> Se \(\det(A) \neq 0\), então a eliminação Gaussiana com pivoteamento gera uma matriz \(A\) com diagonal não nula.</p>
<h2 id=complexidade ><a href="#complexidade" class=header-anchor >Complexidade</a></h2>
<p>Vamos analisar agora a complexidade da eliminação Gaussiana. Vamos recopiar a última versão aqui para referência.</p>
<ol>
<li><p>Entrada:</p>
<ul>
<li><p>matriz \(A\), \(n \times n\)</p>

<li><p>vetor \(b\) de tamanho \(n\)</p>

</ul>

<li><p>Para \(j\) de \(1\) a \(n-1\)</p>
<ol>
<li><p>Encontre a linha \(k = \argmax \{|a_{ij}| : i = j,\dots,n\}\) onde fica o pivô.</p>

<li><p>Faça \(L_k \leftrightarrow L_j\)</p>

<li><p>Faça \(b_k \leftrightarrow b_j\)</p>

<li><p>Para \(i\) de \(j+1\) a \(n\)</p>
<ol>
<li><p>Calcule \(m_{ij} = a_{ij}/a_{jj}\)</p>

<li><p>Faça \(L_i \leftarrow L_i - m_{ij}L_j\)</p>

<li><p>Faça \(b_i \leftarrow b_i - m_{ij}b_j\)</p>

</ol>

</ol>

<li><p>Saída:</p>
<ul>
<li><p>\(A\) triangular superior</p>

<li><p>\(b\) com modificações correspondentes.</p>

</ul>

</ol>
<p>Primeiro o que é mais direto.</p>
<ul>
<li><p>2.4.1: 1 divisão</p>

<li><p>2.4.2: Cada \(a_{i\ell} \leftarrow a_{i\ell} - m_{i j} a_{j\ell}\) são 2 operações.   Fazemos isso para \(\ell = j+1,\dots,n\), logo são \(n - j\) vezes, num total de 2&#40;n-j&#41; operações</p>

<li><p>2.4.3: Mais 2 operações.</p>

</ul>
<p>Um total de \(2(n-j)+3\) operações para cada \(i\).</p>
<p>Agora o loop 2.4. Ele é feito para \(i = j+1,\dots,n\), logo um total de \([2(n-j)+3](n-j) = 2(n-j)^2 + 3(n-j)\) operações para cada \(j\).</p>
<p>Os passos 2.1-2.3 não muito se feitos corretamente.</p>
<p>O total \(2(n-j)^2 + 3(n-j)\) é feito para cada \(j = 1,\dots,n-1\), que dá</p>
\[\begin{aligned}
\sum_{j=1}^{n-1}[2(n-j)^2 + 3(n-j)]
& = \sum_{j=1}^{n-1}(2j^2 + 3j) \\
& = 2\frac{(n-1)n(2n-1)}{6} + 3\frac{(n-1)n}{2} \\
& = \frac{2}{3}n^3 + \frac{1}{2}n^2 - \frac{7}{6}n.
\end{aligned}\]
<p>Agora, a complexidade da resolução do sistema triangular.</p>
<ol>
<li><p>Entrada:</p>
<ul>
<li><p>\(A\), \(n \times n\) triangular superior com diagonal não-nula</p>

<li><p>\(b\), tamanho \(n\)</p>

</ul>

<li><p>Crie o vetor \(x\) nulo</p>

<li><p>Para \(i\) de \(n\) à \(1\), voltando</p>
<ol>
<li><p>\(s \leftarrow x_i\)</p>

<li><p>Para \(j\) de \(i+1\) à \(n\)</p>
<ol>
<li><p>\(s \leftarrow s - a_{ij}x_j\)</p>

</ol>

<li><p>\(x_i = \dfrac{s}{a_{ii}}\)</p>

</ol>

<li><p>Saída:</p>
<ul>
<li><p>\(x\): solução de \(Ax = b\)</p>

</ul>

</ol>
<p>Essa é um pouco mais fácil de se calcular. A operação 2.2.2 faz \(2(n-j)\) operações para cada \(j\) num total de \(2(n-j) + 1\) por \(j\). Logo, temos</p>
\[\begin{aligned}
\sum_{j=1}^n [2(n-j) + 1]
& = \sum_{j=0}^{n-1}[2j + 1] \\
& = 2\sum_{j=0}^{n-1}j + n \\
& = (n-1)n + n = n^2.
\end{aligned}\]
<p>Portanto, para resolver do zero um sistema linear \(Ax = b\) pela eliminação Gaussiana, fazemos</p>
\[ \frac{2}{3}n^3 + \frac{3}{2}n^2 - \frac{7}{6}n. \]
<p>O mais importante nesse valor todo é o \(n^3\). Isso porque ele será o termo que mais &quot;pesa&quot; nessa conta para \(n\) grande. Dizemos que a complexidade é da ordem de \(n^3\).</p>
<p>Note que a complexidade de multiplicar uma matriz por um vetor é de ordem \(n^2\), que é a mesma ordem de resolver um sistema triangular superior. Resolver o sistema do zero, no entanto, é de ordem \(n^3\), que é a mesma ordem de multiplicar duas matrizes \(n\) por \(n\).</p>
<h2 id="decomposição_lu"><a href="#decomposição_lu" class=header-anchor >Decomposição LU</a></h2>
<pre><code class=language-julia >A &#61; &#91;4.0 3 2; 2 5 -1; 1 -2 0&#93;

m21 &#61; 2 / 4
#L₂ - m₂₁L₁  equivale a E₂₁ × A
E21 &#61; diagm&#40;0 &#61;&gt; ones&#40;3&#41;&#41; # Identidate
E21&#91;2,1&#93; &#61; -m21
E21</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
  1.0  0.0  0.0
 -0.5  1.0  0.0
  0.0  0.0  1.0</code></pre>
<pre><code class=language-julia >E21 * A</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 4.0   3.0   2.0
 0.0   3.5  -2.0
 1.0  -2.0   0.0</code></pre>
<pre><code class=language-julia >m31 &#61; A&#91;3,1&#93; / A&#91;1,1&#93;
E31 &#61; diagm&#40;0 &#61;&gt; ones&#40;3&#41;&#41; # Identidate
E31&#91;3,1&#93; &#61; -m31
E31</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
  1.0   0.0  0.0
  0.0   1.0  0.0
 -0.25  0.0  1.0</code></pre>
<pre><code class=language-julia >E31 * E21 * A</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 4.0   3.0    2.0
 0.0   3.5   -2.0
 0.0  -2.75  -0.5</code></pre>
<pre><code class=language-julia >E31 * E21</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
  1.0   0.0  0.0
 -0.5   1.0  0.0
 -0.25  0.0  1.0</code></pre>
<pre><code class=language-julia >A2 &#61; E31 * E21 * A</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 4.0   3.0    2.0
 0.0   3.5   -2.0
 0.0  -2.75  -0.5</code></pre>
<pre><code class=language-julia >m32 &#61; A2&#91;3,2&#93; / A2&#91;2,2&#93;
E32 &#61; diagm&#40;0 &#61;&gt; ones&#40;3&#41;&#41; # Identidate
E32&#91;3,2&#93; &#61; -m32
E32</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 1.0  0.0       0.0
 0.0  1.0       0.0
 0.0  0.785714  1.0</code></pre>
<pre><code class=language-julia >E32 * A2</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 4.0  3.0   2.0
 0.0  3.5  -2.0
 0.0  0.0  -2.07143</code></pre>
<pre><code class=language-julia >E32 * E31 * E21 * A</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 4.0          3.0   2.0
 0.0          3.5  -2.0
 2.22045e-16  0.0  -2.07143</code></pre>
<pre><code class=language-julia >E32 * E31 * E21</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
  1.0       0.0       0.0
 -0.5       1.0       0.0
 -0.642857  0.785714  1.0</code></pre>
<pre><code class=language-julia >inv&#40;E32 * E31 * E21&#41;</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 1.0    0.0       0.0
 0.5    1.0       0.0
 0.25  -0.785714  1.0</code></pre>
<pre><code class=language-julia >inv&#40;E21&#41;</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 1.0  0.0  0.0
 0.5  1.0  0.0
 0.0  0.0  1.0</code></pre>
<pre><code class=language-julia >inv&#40;E31&#41;</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 1.0   0.0  0.0
 0.0   1.0  0.0
 0.25  0.0  1.0</code></pre>
<pre><code class=language-julia >inv&#40;E32&#41;</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 1.0   0.0       0.0
 0.0   1.0       0.0
 0.0  -0.785714  1.0</code></pre>
<pre><code class=language-julia >inv&#40;E21&#41; * inv&#40;E31&#41; * inv&#40;E32&#41;</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 1.0    0.0       0.0
 0.5    1.0       0.0
 0.25  -0.785714  1.0</code></pre>
<pre><code class=language-julia >L &#61; diagm&#40;0 &#61;&gt; ones&#40;3&#41;&#41;
L&#91;2,1&#93; &#61; m21
L&#91;3,1&#93; &#61; m31
L&#91;3,2&#93; &#61; m32
L</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 1.0    0.0       0.0
 0.5    1.0       0.0
 0.25  -0.785714  1.0</code></pre>
<pre><code class=language-julia >U &#61; E32 * E31 * E21 * A</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 4.0          3.0   2.0
 0.0          3.5  -2.0
 2.22045e-16  0.0  -2.07143</code></pre>
<pre><code class=language-julia >L * U</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 4.0   3.0   2.0
 2.0   5.0  -1.0
 1.0  -2.0   0.0</code></pre>
<pre><code class=language-julia >L * U - A</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 0.0          0.0  0.0
 0.0          0.0  0.0
 2.22045e-16  0.0  0.0</code></pre>
<p>Como \(A = LU\), o sistema \(Ax = b\) vira \(LUx = b\), ou seja</p>
\[x = U^{-1} L^{-1} b.\]
<pre><code class=language-julia >b &#61; A * ones&#40;3&#41;
&#40;U \ &#40;L \ b&#41;&#41;</code></pre><pre><code class=plaintext >3-element Vector{Float64}:
 0.9999999999999998
 1.0000000000000002
 1.0000000000000002</code></pre>
<pre><code class=language-julia >function declu&#40;A::Matrix; diagtol &#61; 1e-12&#41;
    n &#61; size&#40;A, 1&#41;
    for j &#61; 1:n-1
        ajj &#61; A&#91;j,j&#93;
        if abs&#40;ajj&#41; &lt;&#61; diagtol
            error&#40;&quot;Diagonal muito próxima de 0&quot;&#41;
        end
        Lj &#61; A&#91;j,j&#43;1:n&#93;
        for i &#61; j&#43;1:n
            mij &#61; A&#91;i,j&#93; / ajj
            A&#91;i,j&#43;1:n&#93; &#61; A&#91;i,j&#43;1:n&#93; - mij * Lj
            A&#91;i,j&#93; &#61; mij
        end
    end
    return tril&#40;A,-1&#41; &#43; I, triu&#40;A&#41;
end

A &#61; &#91;3.0 1 2; -1 2 1; 1 1 4&#93;
L, U &#61; declu&#40;copy&#40;A&#41;&#41;</code></pre><pre><code class=plaintext >([1.0 0.0 0.0; -0.3333333333333333 1.0 0.0; 0.3333333333333333 0.28571428571428575 1.0], [3.0 1.0 2.0; 0.0 2.3333333333333335 1.6666666666666665; 0.0 0.0 2.857142857142857])</code></pre>
<pre><code class=language-julia >L</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
  1.0       0.0       0.0
 -0.333333  1.0       0.0
  0.333333  0.285714  1.0</code></pre>
<pre><code class=language-julia >U</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 3.0  1.0      2.0
 0.0  2.33333  1.66667
 0.0  0.0      2.85714</code></pre>
<pre><code class=language-julia >L * U - A</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 0.0  0.0           0.0
 0.0  0.0          -1.11022e-16
 0.0  2.22045e-16   0.0</code></pre>
<pre><code class=language-julia >A &#61; rand&#40;3, 3&#41;
L, U &#61; declu&#40;copy&#40;A&#41;&#41;
norm&#40;L * U - A&#41;</code></pre><pre><code class=plaintext >0.0</code></pre>
<pre><code class=language-julia >A &#61; rand&#40;3, 3&#41;</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 0.775188   0.682194  0.651778
 0.177409   0.92936   0.596532
 0.0800227  0.973119  0.479261</code></pre>
<pre><code class=language-julia >tril&#40;A, -1&#41; &#43; I</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 1.0        0.0       0.0
 0.177409   1.0       0.0
 0.0800227  0.973119  1.0</code></pre>
<pre><code class=language-julia >triu&#40;A&#41;</code></pre><pre><code class=plaintext >3×3 Matrix{Float64}:
 0.775188  0.682194  0.651778
 0.0       0.92936   0.596532
 0.0       0.0       0.479261</code></pre>
<p>No ponto atual, conseguimos resolver um sistema linear, sobre algumas condições. Temos um problema, no entanto, e se quisermos resolver mais de um sistema linear, e não tivermos todas os vetores do lado direito de imediato?</p>
<p>Isso acontece com frequência em muitas aplicações. Em particular, em otimização linear e não-linear com restrições lineares, essa situação é bastante comum. Também para o cálculo de autovalores e autovetores de uma matriz, existe um método que faz isso. De maneira geral, é como se a matriz \(A\) fosse uma parte fixa de um modelo e o vetor \(b\) fosse uma parte móvel.</p>
<p>Se precisamos resolver muitos sistemas com a mesma matriz \(A\), e começarmos do zero todos eles, teremos uma complexidade de ordem \(n^3\)<strong>para cada iteração desse método</strong>. No entanto, se tivermos os valores de \(m_{ij}\), podemos fazer as operações necessárias apenas no vetor do lado direito.</p>
<p>Note que temos \(\dfrac{(n-1)n}{2}\) elementos \(m_{ij}\) para guardar. Não por acaso, eles equivalem a cada um dos zeros da matriz \(A\) final. Sendo assim, podemos <strong>utilizar a própria matriz \(A\) para guardar \(m_{ij}\).</strong></p>
<p>Note também, que precisamos guardar as permutações que foram feitas, pois as linhas do vetor do lado direito também precisam ser trocadas. Por enquanto, para facilitar o entendimento, vamos considerar a eliminação sem pivoteamento novamente.</p>
<p>Também precisamos criar uma função para aplicar os valores de \(m_{ij}\) à um vetor \(b\). No entanto, veja que podemos ir direto ao objetivo e aproveitar e resolver o sistema logo. Note que a aplicação dos \(m_{ij}\) modifica o vetor \(b\), e além disso criamos um novo vetor \(x\). Isso quer dizer que estamos</p>
<ul>
<li><p>perdendo o \(b\) original; e</p>

<li><p>gastando mais memória com \(x\).</p>

</ul>
<p>Podemos resolver um desses problemas. As opções são</p>
<ol>
<li><p>Copiar o \(b\) para o \(x\), aplicar \(m_{ij}\) no \(x\) e resolver o sistema modificando o \(x\) para ser a solução no fim; ou</p>

<li><p>Aplicar \(m_{ij}\) em \(b\), e resolver o sistema modificando o \(b\) para ser a solução no fim.</p>

</ol>
<p>A opção 1 resolve o problema de perder \(b\). Ao fim teremos \(b\) e um novo \(x\) que será a solução de \(Ax = b\).</p>
<p>A opção 2 resolve o problema de gastar memória. Perderemos \(b\), mas teremos a solução sem gasto de memória adicional.</p>
<p>A segunda opção é melhor pois se quisermos manter \(b\), podemos copiar \(b\) antes de chamar a função.</p>
<ol>
<li><p>Entrada:</p>
<ul>
<li><p>\(A\), \(n \times n\) onde a parte triangular superior é corresponde ao resultado</p>

</ul>
<p>da eliminação Gaussiana, e a parte triangular inferior sem a diagonal  corresponde aos valores \(m_{ij}\)</p>
<ul>
<li><p>\(b\), de tamanho \(n\) que será modificado para guardar a solução do sistema.</p>

</ul>

<li><p>Para \(i\) de \(1\) a \(n\)</p>
<ol>
<li><p>Para \(j\) de \(1\) a \(i-1\)</p>
<ol>
<li><p>Faça \(b_i \leftarrow b_i - a_{ij}b_j\)</p>

</ol>

</ol>

<li><p>Para \(1\) de \(n\) à \(1\), voltando</p>
<ol>
<li><p>\(s \leftarrow b_i\)</p>

<li><p>Para \(j\) de \(i+1\) à \(n\)</p>
<ol>
<li><p>\(s \leftarrow s - a_{ij}b_j\)</p>

</ol>

<li><p>\(b_i = \dfrac{s}{a_{ii}}\)</p>

</ol>

</ol>
<pre><code class=language-julia >function resolvelu&#40;L, U, b&#41;
    n &#61; length&#40;b&#41;
    #Ly &#61; b
    y &#61; zeros&#40;n&#41;
    for i &#61; 1:n
        s &#61; 0.0
        for j &#61; 1:i-1
            s &#43;&#61; L&#91;i,j&#93; * y&#91;j&#93;
        end
        y&#91;i&#93; &#61; b&#91;i&#93; - s
    end

    #Ux &#61; y
    x &#61; zeros&#40;n&#41;
    for i &#61; n:-1:1
        s &#61; 0.0
        for j &#61; i&#43;1:n
            s &#43;&#61; U&#91;i,j&#93; * x&#91;j&#93;
        end
        x&#91;i&#93; &#61; &#40;y&#91;i&#93; - s&#41; / U&#91;i,i&#93;
    end
    return x
end

A &#61; &#91;3.0 1 2; -1 2 1; 1 1 4&#93;
b &#61; A * ones&#40;3&#41;

L, U &#61; declu&#40;copy&#40;A&#41;&#41;
x &#61; resolvelu&#40;L, U, b&#41;</code></pre><pre><code class=plaintext >3-element Vector{Float64}:
 1.0
 1.0000000000000002
 0.9999999999999999</code></pre>
<p>Vamos analisar a primeira parte de <code>resolvelu</code> com mais detalhes, pensando num caso 3x3.</p>
<pre><code class=language-julia >x é o valor de saída
Começo x₁ &#61; b₁, x₂ &#61; b₂, x₃ &#61; b₃
j &#61; 1
  i &#61; 2
    x₂ ← x₂ - m₂₁x₁
  i &#61; 3
    x₃ ← x₃ - m₃₁x₁
j &#61; 2
  i &#61; 3
    x₃ ← x₃ - m₃₂x₂</code></pre>
<p>No final desse processo temos as seguintes relações</p>
\[\begin{aligned}\left\{\begin{array}{rcl}
x_1 & = & b_1 \\
x_2 & = & b_2 - m_{21} x_1 \\
x_3 & = & b_3 - m_{31} x_1 - m_{32} x_2.
\end{array}\right.
\end{aligned}\]
<p>Isso quer dizer que</p>
\[\begin{aligned}\left\{
\begin{array}{rcrcrcl}
      x_1 & &           & &     & = & b_1 \\
m_{21}x_1 &+&       x_2 & &     & = & b_2 \\
m_{31}x_1 &+& m_{32}x_2 &+& x_3 & = & b_3
\end{array}\right.
\end{aligned}\]
<p>Que corresponde ao sistema linear \(Lx = b\), onde \(L\) é a matriz</p>
\[\left[\begin{array}{ccc}
1 & 0 & 0 \\
m_{21} & 1 & 0 \\
m_{31} & m_{32} & 1
\end{array}\right].\]
<p>Isso quer dizer que fazer eliminação Gaussiana em \(\left[\begin{array}{cc}A & b\end{array}\right]\) é equivalente a fazer eliminação Gaussiana apenas em \(A\), guardar \(m_{ij}\) em \(L\) e calcular \(L^{-1}b\). Note que \(\det(L) = 1\) e por isso sempre existe a inversa.</p>
<p>Chamando a matriz resultante da eliminação Gaussiana em \(A\) de \(U\), podemos dizer que começamos com o sistema</p>
\[ Ax = b, \]
<p>e acabamos com o sistema</p>
\[ Ux = L^{-1}b. \]
<p>Mas então podemos fazer</p>
\[ LUx = b. \]
<p>Será que \(A = LU\)? A resposta é sim, pois os valores de \(x\) e \(b\) não são usados para se calcular nem \(L\) nem \(U\). Portanto, podemos mudar \(x\) e obter um \(b\) correspondente, e os dois sistemas continuarão válidos. Outra maneira de ver isso é subtrair os dois sistemas, obtendo \((A - LU)x = 0\), e variar \(x\) para cada coluna da identidade.</p>
<p>Concluindo, o processo de eliminação Gaussiana nos dá uma maneira de representar \(A\) que depende de duas matrizes mais simples. Chamamos essa maneira de <strong>fatoração LU</strong>.</p>
<p>Existem várias fatorações matriciais. Algumas são bem conhecidas, e algumas são bem específicas. A fatoração LU é a mais famosa, pois não depende de nenhuma propriedade especial da matriz para existe, com exceção do Teorema que passamos.</p>
<p>Dado a fatoração \(LU\) da matriz \(A\), não iremos mais pensar em resolver \(Ax = b\) como a aplicação da eliminação Gaussiana, e sim como a resolução de sistemas triangulares.</p>
<p>Dado \(Ax = b\), e \(A = LU\), temos</p>
\[ LUx = b. \]
<p>Para resolver esse sistema, fazemos \(Ux = y\), obtendo</p>
\[ \left\{\begin{array}{rcl}
Ly & = & b \\
Ux & = & y.
\end{array}\right. \]
<p>Dessa maneira, fica óbvio que resolvemos dois sistemas triangulares.</p>
<p>Para resolver o sistema triangular \(Ly = b\), veja que</p>
\[\left\{\begin{array}{rcl}
y_1 & = & b_1 \\
y_2 & = & b_2 - m_{21}y_1 \\
y_3 & = & b_3 - m_{31}y_1 - m_{32}y_2 \\
\vdots & & \vdots \\
y_n & = & b_n - \sum_{j=1}^{n-1} m_{nj} y_j.
\end{array}\right.\]
<p>Em outras palavras,</p>
\[ y_i = b_i - \sum_{j = 1}^{i - 1}m_{ij} y_j, \qquad i = 1,\dots,n. \]
<p>Veja que se calculamos na ordem natural \(1,\dots,n\), teremos os valores necessários para definir todos os \(y_i\).</p>
<p>Abaixo vemos o algoritmo para resolver esse sistema, e vamos substituir \(b\) de entrada pelo valor de \(y\) de saída.</p>
<ol>
<li><p><strong>Entrada</strong></p>

</ol>
<ul>
<li><p>L: \(n \times n\) triangular inferior com diagonal de 1</p>

<li><p>b: tamanho \(n\)</p>

</ul>
<ol start=2 >
<li><p>Para \(i\) de \(1\) à \(n-1\)</p>
<ol>
<li><p>Para \(j\) de \(1\) à \(i-1\)</p>
<ol>
<li><p>\(b_i \leftarrow b_i - m_{ij} b_j\)</p>

</ol>

</ol>

</ol>
<p>Comparando com o algoritmo que faz a eliminação Gaussiana em \(b\), vemos uma leva diferença</p>
<p>Algoritmo que faz elim. Gauss. em b</p>
<ol>
<li><p>Para \(j\) de \(1\) a \(n-1\)</p>
<ol>
<li><p>Para \(i\) de \(j+1\) a \(n\)</p>
<ol>
<li><p>Faça \(b_i \leftarrow b_i - a_{ij} b_j\)</p>

</ol>

</ol>

</ol>
<p>A ordem desse algoritmo está diferente, e os limites para os loops de \(i\) e \(j\) também. No entanto, a operação que é calculada é a mesma &#40;lembre-se que \(a_{ij} = m_{ij}\)&#41;.</p>
<h3 id="fatoração_lu_com_pivoteamento"><a href="#fatoração_lu_com_pivoteamento" class=header-anchor >Fatoração LU com pivoteamento</a></h3>
<p>Como vimos anteriormente, a qualidade da solução do sistema pela eliminação Gaussiana, muda drasticamente quanto utilizamos pivotamento. Na fatoração LU, isso também é verdade.</p>
<p>Agora que guardamos a matriz \(L\), o pivoteamento também irá afetá-la. Além disso, queremos calcular a fatoração sem a necessidade de um vetor do lado direito, então precisamos guardar o pivoteamento feito para fazê-lo no vetor \(b\) também.</p>
<pre><code class=language-julia >A &#61; &#91; 1  3  0  1;
      2  1  1  1;
     -3 -1 -1 -3;
     -1 -1  0 -1.0&#93;
B &#61; copy&#40;A&#41;
p &#61; &#91;1;2;3;4&#93;

#pivô: a₃₁, L₁ ↔ L₃
p&#91;3&#93;, p&#91;1&#93; &#61; p&#91;1&#93;, p&#91;3&#93;
A&#91;3,:&#93;, A&#91;1,:&#93; &#61; A&#91;1,:&#93;, A&#91;3,:&#93;
A</code></pre><pre><code class=plaintext >4×4 Matrix{Float64}:
 -3.0  -1.0  -1.0  -3.0
  2.0   1.0   1.0   1.0
  1.0   3.0   0.0   1.0
 -1.0  -1.0   0.0  -1.0</code></pre>
<pre><code class=language-julia >m &#61; A&#91;2:4,1&#93; / A&#91;1,1&#93;
A&#91;2:4,1&#93; &#61; m
A&#91;2:4,2:4&#93; -&#61; m * A&#91;1,2:4&#93;&#39;
A</code></pre><pre><code class=plaintext >4×4 Matrix{Float64}:
 -3.0       -1.0       -1.0       -3.0
 -0.666667   0.333333   0.333333  -1.0
 -0.333333   2.66667   -0.333333   0.0
  0.333333  -0.666667   0.333333   0.0</code></pre>
<pre><code class=language-julia >p&#39;</code></pre><pre><code class=plaintext >1×4 adjoint(::Vector{Int64}) with eltype Int64:
 3  2  1  4</code></pre>
<pre><code class=language-julia >#pivô: a₃₂, L₂ ↔ L₃
p&#91;3&#93;, p&#91;2&#93; &#61; p&#91;2&#93;, p&#91;3&#93;
A&#91;3,:&#93;, A&#91;2,:&#93; &#61; A&#91;2,:&#93;, A&#91;3,:&#93;
A</code></pre><pre><code class=plaintext >4×4 Matrix{Float64}:
 -3.0       -1.0       -1.0       -3.0
 -0.333333   2.66667   -0.333333   0.0
 -0.666667   0.333333   0.333333  -1.0
  0.333333  -0.666667   0.333333   0.0</code></pre>
<pre><code class=language-julia >m &#61; A&#91;3:4,2&#93; / A&#91;2,2&#93;
A&#91;3:4,2&#93; &#61; m
A&#91;3:4,3:4&#93; -&#61; m * A&#91;2,3:4&#93;&#39;
A

#pivô: a₃₃, não há troca
m &#61; A&#91;4,3&#93; / A&#91;3,3&#93;
A&#91;4,3&#93; &#61; m
A&#91;4,4&#93; -&#61; m * A&#91;3,4&#93;
A</code></pre><pre><code class=plaintext >4×4 Matrix{Float64}:
 -3.0       -1.0      -1.0       -3.0
 -0.333333   2.66667  -0.333333   0.0
 -0.666667   0.125     0.375     -1.0
  0.333333  -0.25      0.666667   0.666667</code></pre>
<pre><code class=language-julia >L &#61; tril&#40;A, -1&#41; &#43; I</code></pre><pre><code class=plaintext >4×4 Matrix{Float64}:
  1.0        0.0    0.0       0.0
 -0.333333   1.0    0.0       0.0
 -0.666667   0.125  1.0       0.0
  0.333333  -0.25   0.666667  1.0</code></pre>
<pre><code class=language-julia >U &#61; triu&#40;A&#41;</code></pre><pre><code class=plaintext >4×4 Matrix{Float64}:
 -3.0  -1.0      -1.0       -3.0
  0.0   2.66667  -0.333333   0.0
  0.0   0.0       0.375     -1.0
  0.0   0.0       0.0        0.666667</code></pre>
<pre><code class=language-julia >p&#39;</code></pre><pre><code class=plaintext >1×4 adjoint(::Vector{Int64}) with eltype Int64:
 3  1  2  4</code></pre>
<pre><code class=language-julia >P &#61; Matrix&#40;1.0I, 4, 4&#41;&#91;p,:&#93;</code></pre><pre><code class=plaintext >4×4 Matrix{Float64}:
 0.0  0.0  1.0  0.0
 1.0  0.0  0.0  0.0
 0.0  1.0  0.0  0.0
 0.0  0.0  0.0  1.0</code></pre>
<p>O vetor \(p\) corresponde à uma <strong>matriz de permutação</strong> \(P\). Uma matriz de permutação é uma matriz obtida a partir de permutações de linhas e permutações de colunas na matriz identidade.</p>
<ul>
<li><p>Se a matriz \(P\) é obtida a partir de uma sequência de permutações nas <strong>linhas</strong> da matriz identidade, então a matriz \(PA\) é a matriz resultante das mesmas permutações nas linhas de \(A\). Nesse caso, dizemos que \(P\) é uma <strong>matriz de permutação de linhas</strong>.</p>

<li><p>Análogo para colunas, e para a matriz \(AP\).</p>

</ul>
<p>O vetor \(p\) tem os índices dessas linhas. Inicialmente, \(p\) é um vetor com \(p_i = i\), que significa que \(P\) é a identidade. Cada modificação no passo XXX modifica elementos de \(p\) e as linhas correspondentes de \(P\).</p>
<p>Uma matriz de permutação de linhas também é uma matriz de permutação de colunas, mas com outras permutações &#40;a priori indetermidanas&#41;.</p>
<p><strong>Exercício:</strong> Mostre que se \(P\) é uma matriz de permutação de linhas, então \(P^T\) é uma matriz de permutação de colunas.</p>
<p>Uma parte não trivial do processo da fatoração LU com pivoteamento é descobrir a relação entre \(A\), \(L\), \(U\) e \(P\). Como não dispomos do tempo, vamos simplesmente enunciar essa relação.</p>
<p><strong>Teo.:</strong> Se \(A\) é não-singular, o algoritmo de fatoração LU com pivoteamento parcial da matriz \(A\) retorna matrizes \(L\), \(U\) e \(P\) tais que</p>
\[ PA = LU. \]
<pre><code class=language-julia >P * B - L * U

B&#91;p,:&#93; - L * U</code></pre><pre><code class=plaintext >4×4 Matrix{Float64}:
 0.0  0.0   0.0          0.0
 0.0  0.0   0.0          0.0
 0.0  0.0   0.0          0.0
 0.0  0.0  -9.25186e-18  0.0</code></pre>
\[\begin{aligned}
Ax & = b \\
PAx & = Pb \\
LUx & = Pb.
\end{aligned}\]
<p>Daí, temos</p>
\[\left\{
\begin{array}{rcl}
c & = & Pb \\
Ly & = & c \\
Ux & = & y
\end{array}
\right.\]
<pre><code class=language-julia >b &#61; B * ones&#40;4&#41;

c &#61; b&#91;p&#93;
y &#61; L \ c
x &#61; U \ y</code></pre><pre><code class=plaintext >4-element Vector{Float64}:
 1.0000000000000002
 1.0000000000000002
 0.9999999999999999
 0.9999999999999998</code></pre>
<p>A implementação do algoritmo está abaixo.</p>
<pre><code class=language-julia >function declupivot&#40;A::Matrix; diagtol &#61; 1e-12&#41;
    n &#61; size&#40;A, 2&#41;
    p &#61; collect&#40;1:n&#41;
    for j &#61; 1:n-1
        #Quem é o pivô
        pivo, k &#61; abs&#40;A&#91;j,j&#93;&#41;, j
        for i &#61; j&#43;1:n
            if abs&#40;A&#91;i,j&#93;&#41; &gt; pivo
                pivo, k &#61; abs&#40;A&#91;i,j&#93;&#41;, i
            end
        end
        if pivo &lt;&#61; diagtol
            error&#40;&quot;Matriz singular ou muito próxima de ser singular&quot;&#41;
        end

        if k &#33;&#61; j
            p&#91;k&#93;, p&#91;j&#93; &#61; p&#91;j&#93;, p&#91;k&#93;
            A&#91;&#91;k;j&#93;,:&#93; &#61; A&#91;&#91;j;k&#93;,:&#93;
        end
        ajj &#61; A&#91;j,j&#93;
        for i &#61; j&#43;1:n
            mij &#61; A&#91;i,j&#93; / ajj
            A&#91;i,j&#93; &#61; mij
            A&#91;i,j&#43;1:n&#93; -&#61; mij * A&#91;j,j&#43;1:n&#93;
        end
    end
    return p
end

A &#61; &#91; 1  3  0  1;
      2  1  1  1;
     -3 -1 -1 -3;
     -1 -1  0 -1.0&#93;
p &#61; declupivot&#40;A&#41;
A</code></pre><pre><code class=plaintext >4×4 Matrix{Float64}:
 -3.0       -1.0      -1.0       -3.0
 -0.333333   2.66667  -0.333333   0.0
 -0.666667   0.125     0.375     -1.0
  0.333333  -0.25      0.666667   0.666667</code></pre>
<h2 id="exercícios"><a href="#exercícios" class=header-anchor >Exercícios</a></h2>
<p>Exercícios do capítulo 3 do livro Cálculo Numérico de Ruggiero e Lopes, com exceção daqueles que não competem ao assunto.</p>
<ol>
<li><p>Sabendo que \(P^TP = I\), mostre como resolver o sistema linear \(A^T\lambda = c\) usando a fatoração LU.</p>

<li><p>Quando a matriz \(A\) é sobrescrita pela fatoração \(LU\), nada é perdido. Faça um algoritmo que descreve como calcular o produto \(Ax\) pra um vetor \(x\) quando a matriz \(A\) foi sobrescrita. Compare o número de operações nesse produto com o número de operações no produto com \(A\) na forma original.</p>

<li><p>Escreva um algoritmo de fatoração LU e resolução de sistema para matrizes tridiagonais, usando como entrada apenas 3 vetores, correspondentes às diagonais existentes da matriz.</p>

<li><p>Uma matriz singular pode não ter fatoração \(LU\) da maneira que vimos. No entanto, é possível estender a fatoração para continuar o processo, mesmo se encontrarmos um zero na diagonal. Estude como fazer isso. Teste com matrizes cuja primeira coluna é nula. Compare com o <code>lu</code> já implementado no Julia.</p>

<li><p>Uma matriz não quadrada também pode ter fatoração LU, estendo o conceito da questão anterior. Estude como fazer isso.</p>

<li><p>*Uma matriz de banda é uma extensão da matriz tridiagonal. Uma matriz com bandas \(a \geq 0\) e \(b \geq 0\) é uma matriz \(A\) com \(a\) diagonais abaixo da diagonal e \(b\) diagonais acima da diagonal. Se \(a = b = 1\), a matriz é tridiagonal. Para representar uma matriz de banda \(A \in \mathbb{R}^{n\times n}\), costuma-se usar uma matriz \(D \in \mathbb{R}^{1+a+b}\times n\), onde cada linha corresponde à uma diagonal de \(A\).</p>

</ol>
<p>Escreva um algoritmo que faz a fatoração LU dessa matriz de banda e resolve um sistema linear usando essa fatoração. Descreva a posição dos elementos de \(A\) na matriz \(D\).</p>
<ol>
<li><p>*O pivoteamento da fatoração LU é feito sempre que algum elemento da coluna abaixo da diagonal é maior que o elemento da diagonal. Porém, trocar linhas também é custoso, então podemos fazer um compromisso entre melhorar a estabilidade e diminuir a troca de linhas usando a condição a seguir:</p>

</ol>
\[ \text{se existe $i > j$ tal que } \qquad
|a_{ij}| > \alpha |a_{jj}|,
\qquad \text{ então faça a troca}. \]
<p>A constante \(\alpha \geq 1\) define o nível do compromisso. Se \(\alpha = 1\) temos o pivotamento visto acima. Se \(\alpha \rightarrow \infty\), então a troca só é feita se \(a_{jj} = 0\). Faça um algoritmo que implementa essa mudança, com \(\alpha\) sendo um parâmetro opcional de entrada.</p>
<ol>
<li><p>*O pivoteamento de linhas para diminuição da esparsidade pode ser feito buscando a linha que tem a maior quantidade de zeros. Deve-se apenas tomar cuidado para que não se piore demais a estabilidade do método.</p>

</ol>
<p>Modificando a condição acima, escreva e implemente o algoritmo que faz um pivoteamento buscando a esparsidade.</p>

</div>
</div>
</div>

<footer>
<div class="container-fluid text-center social-footer">
    <a href="mailto:abel.s.siqueira@gmail.com">
        <i class="fas fa-2x fa-envelope" aria-hidden=true ></i>
    </a><a href="https://github.com/abelsiqueira">
        <i class="fab fa-2x fa-github-square" aria-hidden=true ></i>
    </a><a href="https://linkedin.com/in/abel-siqueira/">
        <i class="fab fa-2x fa-linkedin" aria-hidden=true ></i>
    </a><a href="https://twitter.com/abel_siqueira">
        <i class="fab fa-2x fa-twitter-square" aria-hidden=true ></i>
    </a><a href="https://www.researchgate.net/profile/Abel_Siqueira">
        <i class="fab fa-2x fa-researchgate" aria-hidden=true ></i>
    </a><a href="http://orcid.org/0000-0003-4451-281X">
        <i class="fab fa-2x fa-orcid" aria-hidden=true ></i>
    </a>
</div>
</footer>


<script src="/calculo-numerico/libs/katex/katex.min.js"></script>
<script src="/calculo-numerico/libs/katex/auto-render.min.js"></script>
<script>renderMathInElement(document.body)</script>



<script src="/calculo-numerico/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>


<script src="/calculo-numerico/libs/bootstrap.bundle.min.js" crossorigin=anonymous ></script>
<script src="https://kit.fontawesome.com/d17d5e5245.js" crossorigin=anonymous ></script>
<script type="text/javascript" src="https://cdn.rawgit.com/pcooksey/bibtex-js/ef59e62c/src/bibtex_js.js"></script>